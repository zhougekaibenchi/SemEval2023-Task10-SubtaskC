2023-01-22 22:18:20,712 - DEBUG - tpu_cluster_resolver.py:35 - <module>() - Falling back to TensorFlow client; we recommended you install the Cloud TPU client directly with pip install cloud-tpu-client.
2023-01-22 22:18:20,966 - DEBUG - __init__.py:47 - <module>() - Creating converter from 7 to 5
2023-01-22 22:18:20,966 - DEBUG - __init__.py:47 - <module>() - Creating converter from 5 to 7
2023-01-22 22:18:20,967 - DEBUG - __init__.py:47 - <module>() - Creating converter from 7 to 5
2023-01-22 22:18:20,967 - DEBUG - __init__.py:47 - <module>() - Creating converter from 5 to 7
2023-01-22 22:18:28,556 - DEBUG - tpu_cluster_resolver.py:35 - <module>() - Falling back to TensorFlow client; we recommended you install the Cloud TPU client directly with pip install cloud-tpu-client.
2023-01-22 22:18:28,722 - DEBUG - __init__.py:47 - <module>() - Creating converter from 7 to 5
2023-01-22 22:18:28,722 - DEBUG - __init__.py:47 - <module>() - Creating converter from 5 to 7
2023-01-22 22:18:28,722 - DEBUG - __init__.py:47 - <module>() - Creating converter from 7 to 5
2023-01-22 22:18:28,722 - DEBUG - __init__.py:47 - <module>() - Creating converter from 5 to 7
2023-01-22 22:18:31,505 - INFO - main.py:145 - <module>() - ************************** Args Statement *********************************
2023-01-22 22:18:31,505 - INFO - main.py:146 - <module>() - Args: Namespace(apex=True, awp=True, awp_eps=0.01, awp_lr=0.0001, batch_interval=60, cache_dir='deberta-v3-large-pretrain-2', class_nums=11, contrastive_loss='NTXent loss', contrastive_loss_weight=0.2, contrastive_temperature=0.5, decay_name='cosine_warmup', device='cuda', dropout_action='sum', dropout_num=4, dropout_rate=0.2, dynamic_padding=False, epsilon=1e-08, eval_batch_size=100, focal_loss_gamma=2.0, gradient_accumulation_steps=1.0, hidden_size=1024, higher_optimizer='lookahead', learning_rate=1.1e-05, logging_steps=50, loss_fct_name='CrossEntropy loss', max_grad_norm=1.0, max_sequence_length=100, model_head='attention', model_name='deberta-v3-large-pretrain-2', model_save_path='output/', mutisample_dropout=True, nth_awp_end_epoch=15, nth_awp_start_epoch=1, num_epochs=20.0, optimizer_type='AdamW', patience=6, pretrain_model_path='deberta-v3-large-pretrain-2', seed=405, submission_path='output/SUBMISSION_dev_task_c.csv', test_df='data/official data/dev_task_c_entries.csv', train_batch_size=30, train_df='data/official data/starting_ki/train_all_tasks.csv', use_class_weights=False, use_weighted_sampler=True, warmup_ratio=0.1, weight_decay=0.01, what_to_contrast='sample')
2023-01-22 22:18:35,353 - DEBUG - cmd.py:810 - execute() - Popen(['git', 'version'], cwd=E:\SemEval2023\Task_10_ALL\Task_10_Singletask_C, universal_newlines=False, shell=None, istream=None)
2023-01-22 22:18:35,618 - DEBUG - cmd.py:810 - execute() - Popen(['git', 'version'], cwd=E:\SemEval2023\Task_10_ALL\Task_10_Singletask_C, universal_newlines=False, shell=None, istream=None)
2023-01-22 22:18:49,556 - INFO - trainer.py:53 - train_model() - ***** Running training *****
2023-01-22 22:18:49,557 - INFO - trainer.py:54 - train_model() -   Num Train examples = 109
2023-01-22 22:18:49,557 - INFO - trainer.py:55 - train_model() -   Num Valid examples = 7
2023-01-22 22:18:49,557 - INFO - trainer.py:56 - train_model() -   Num Epochs = 20
2023-01-22 22:18:49,557 - INFO - trainer.py:57 - train_model() -   Train batch size = 30
2023-01-22 22:18:49,557 - INFO - trainer.py:58 - train_model() -   Batch interval = 60
2023-01-22 22:18:49,557 - INFO - trainer.py:59 - train_model() -   Logging steps = 50
2023-01-22 22:18:49,557 - INFO - trainer.py:60 - train_model() -   Gradient Accumulation steps = 1
2023-01-22 22:19:10,473 - INFO - trainer.py:123 - train_model() - **************************************************
2023-01-22 22:19:10,473 - INFO - trainer.py:124 - train_model() - TRAIN RECORD:
2023-01-22 22:19:10,473 - INFO - trainer.py:125 - train_model() - Fold: 0
2023-01-22 22:19:10,473 - INFO - trainer.py:126 - train_model() - Epoch: 001 [  61/109 ( 56%)]
2023-01-22 22:19:10,494 - INFO - trainer.py:130 - train_model() - Train Loss: 3.07143(3.11523)
2023-01-22 22:19:10,495 - INFO - trainer.py:131 - train_model() - Grad: 47724.707
2023-01-22 22:19:10,495 - INFO - trainer.py:132 - train_model() - LR: 0.0000039159
2023-01-22 22:19:10,495 - INFO - trainer.py:133 - train_model() - Time: 0:00:21
2023-01-22 22:19:10,495 - INFO - trainer.py:134 - train_model() - **************************************************
2023-01-22 22:19:13,157 - INFO - trainer.py:190 - evaluate() - **************************************************
2023-01-22 22:19:13,157 - INFO - trainer.py:191 - evaluate() - Valid RECORD:
2023-01-22 22:19:13,157 - INFO - trainer.py:192 - evaluate() - Fold: 0
2023-01-22 22:19:13,157 - INFO - trainer.py:193 - evaluate() - Epoch: 001 [7/7 (100%)]
2023-01-22 22:19:13,157 - INFO - trainer.py:197 - evaluate() - Valid Loss: 3.29073(3.32478)
2023-01-22 22:19:13,157 - INFO - trainer.py:198 - evaluate() - Macro F1: 0.0413
2023-01-22 22:19:13,157 - INFO - trainer.py:199 - evaluate() - Time: 0:00:03
2023-01-22 22:19:13,158 - INFO - trainer.py:200 - evaluate() - **************************************************
2023-01-22 22:19:33,174 - INFO - trainer.py:123 - train_model() - **************************************************
2023-01-22 22:19:33,174 - INFO - trainer.py:124 - train_model() - TRAIN RECORD:
2023-01-22 22:19:33,174 - INFO - trainer.py:125 - train_model() - Fold: 0
2023-01-22 22:19:33,174 - INFO - trainer.py:126 - train_model() - Epoch: 001 [ 109/109 (100%)]
2023-01-22 22:19:33,194 - INFO - trainer.py:130 - train_model() - Train Loss: 3.04697(3.09494)
2023-01-22 22:19:33,194 - INFO - trainer.py:131 - train_model() - Grad: 62444.539
2023-01-22 22:19:33,194 - INFO - trainer.py:132 - train_model() - LR: 0.0000069972
2023-01-22 22:19:33,194 - INFO - trainer.py:133 - train_model() - Time: 0:00:44
2023-01-22 22:19:33,194 - INFO - trainer.py:134 - train_model() - **************************************************
2023-01-22 22:19:35,852 - INFO - trainer.py:190 - evaluate() - **************************************************
2023-01-22 22:19:35,852 - INFO - trainer.py:191 - evaluate() - Valid RECORD:
2023-01-22 22:19:35,852 - INFO - trainer.py:192 - evaluate() - Fold: 0
2023-01-22 22:19:35,852 - INFO - trainer.py:193 - evaluate() - Epoch: 001 [7/7 (100%)]
2023-01-22 22:19:35,853 - INFO - trainer.py:197 - evaluate() - Valid Loss: 3.26211(3.31092)
2023-01-22 22:19:35,853 - INFO - trainer.py:198 - evaluate() - Macro F1: 0.0162
2023-01-22 22:19:35,853 - INFO - trainer.py:199 - evaluate() - Time: 0:00:03
2023-01-22 22:19:35,853 - INFO - trainer.py:200 - evaluate() - **************************************************
2023-01-22 22:19:35,853 - INFO - function_utils.py:301 - __call__() - EarlyStopping counter: 1 out of 6
2023-01-22 22:20:17,815 - INFO - trainer.py:123 - train_model() - **************************************************
2023-01-22 22:20:17,816 - INFO - trainer.py:124 - train_model() - TRAIN RECORD:
2023-01-22 22:20:17,816 - INFO - trainer.py:125 - train_model() - Fold: 0
2023-01-22 22:20:17,816 - INFO - trainer.py:126 - train_model() - Epoch: 002 [  61/109 ( 56%)]
2023-01-22 22:20:17,834 - INFO - trainer.py:130 - train_model() - Train Loss: 2.74468(3.04896)
2023-01-22 22:20:17,835 - INFO - trainer.py:131 - train_model() - Grad: 66820.406
2023-01-22 22:20:17,835 - INFO - trainer.py:132 - train_model() - LR: 0.0000109131
2023-01-22 22:20:17,835 - INFO - trainer.py:133 - train_model() - Time: 0:01:28
2023-01-22 22:20:17,835 - INFO - trainer.py:134 - train_model() - **************************************************
2023-01-22 22:20:20,509 - INFO - trainer.py:190 - evaluate() - **************************************************
2023-01-22 22:20:20,509 - INFO - trainer.py:191 - evaluate() - Valid RECORD:
2023-01-22 22:20:20,509 - INFO - trainer.py:192 - evaluate() - Fold: 0
2023-01-22 22:20:20,509 - INFO - trainer.py:193 - evaluate() - Epoch: 002 [7/7 (100%)]
2023-01-22 22:20:20,509 - INFO - trainer.py:197 - evaluate() - Valid Loss: 3.12890(3.20735)
2023-01-22 22:20:20,509 - INFO - trainer.py:198 - evaluate() - Macro F1: 0.0505
2023-01-22 22:20:20,509 - INFO - trainer.py:199 - evaluate() - Time: 0:00:03
2023-01-22 22:20:20,509 - INFO - trainer.py:200 - evaluate() - **************************************************
2023-01-22 22:20:59,016 - INFO - trainer.py:123 - train_model() - **************************************************
2023-01-22 22:20:59,016 - INFO - trainer.py:124 - train_model() - TRAIN RECORD:
2023-01-22 22:20:59,016 - INFO - trainer.py:125 - train_model() - Fold: 0
2023-01-22 22:20:59,016 - INFO - trainer.py:126 - train_model() - Epoch: 002 [ 109/109 (100%)]
2023-01-22 22:20:59,042 - INFO - trainer.py:130 - train_model() - Train Loss: 2.32902(2.91813)
2023-01-22 22:20:59,042 - INFO - trainer.py:131 - train_model() - Grad: 125217.805
2023-01-22 22:20:59,042 - INFO - trainer.py:132 - train_model() - LR: 0.0000139944
2023-01-22 22:20:59,042 - INFO - trainer.py:133 - train_model() - Time: 0:02:09
2023-01-22 22:20:59,042 - INFO - trainer.py:134 - train_model() - **************************************************
2023-01-22 22:21:01,720 - INFO - trainer.py:190 - evaluate() - **************************************************
2023-01-22 22:21:01,720 - INFO - trainer.py:191 - evaluate() - Valid RECORD:
2023-01-22 22:21:01,720 - INFO - trainer.py:192 - evaluate() - Fold: 0
2023-01-22 22:21:01,720 - INFO - trainer.py:193 - evaluate() - Epoch: 002 [7/7 (100%)]
2023-01-22 22:21:01,720 - INFO - trainer.py:197 - evaluate() - Valid Loss: 2.75391(2.71899)
2023-01-22 22:21:01,720 - INFO - trainer.py:198 - evaluate() - Macro F1: 0.2260
2023-01-22 22:21:01,721 - INFO - trainer.py:199 - evaluate() - Time: 0:00:03
2023-01-22 22:21:01,721 - INFO - trainer.py:200 - evaluate() - **************************************************
2023-01-22 22:21:48,806 - INFO - trainer.py:123 - train_model() - **************************************************
2023-01-22 22:21:48,807 - INFO - trainer.py:124 - train_model() - TRAIN RECORD:
2023-01-22 22:21:48,807 - INFO - trainer.py:125 - train_model() - Fold: 0
2023-01-22 22:21:48,807 - INFO - trainer.py:126 - train_model() - Epoch: 003 [  61/109 ( 56%)]
2023-01-22 22:21:48,828 - INFO - trainer.py:130 - train_model() - Train Loss: 1.63738(2.69521)
2023-01-22 22:21:48,828 - INFO - trainer.py:131 - train_model() - Grad: 90324.203
2023-01-22 22:21:48,828 - INFO - trainer.py:132 - train_model() - LR: 0.0000139611
2023-01-22 22:21:48,829 - INFO - trainer.py:133 - train_model() - Time: 0:02:59
2023-01-22 22:21:48,829 - INFO - trainer.py:134 - train_model() - **************************************************
2023-01-22 22:21:51,522 - INFO - trainer.py:190 - evaluate() - **************************************************
2023-01-22 22:21:51,522 - INFO - trainer.py:191 - evaluate() - Valid RECORD:
2023-01-22 22:21:51,522 - INFO - trainer.py:192 - evaluate() - Fold: 0
2023-01-22 22:21:51,522 - INFO - trainer.py:193 - evaluate() - Epoch: 003 [7/7 (100%)]
2023-01-22 22:21:51,522 - INFO - trainer.py:197 - evaluate() - Valid Loss: 2.33718(2.39212)
2023-01-22 22:21:51,522 - INFO - trainer.py:198 - evaluate() - Macro F1: 0.3622
2023-01-22 22:21:51,522 - INFO - trainer.py:199 - evaluate() - Time: 0:00:03
2023-01-22 22:21:51,522 - INFO - trainer.py:200 - evaluate() - **************************************************
2023-01-22 22:22:29,835 - INFO - trainer.py:123 - train_model() - **************************************************
2023-01-22 22:22:29,835 - INFO - trainer.py:124 - train_model() - TRAIN RECORD:
2023-01-22 22:22:29,835 - INFO - trainer.py:125 - train_model() - Fold: 0
2023-01-22 22:22:29,835 - INFO - trainer.py:126 - train_model() - Epoch: 003 [ 109/109 (100%)]
2023-01-22 22:22:29,856 - INFO - trainer.py:130 - train_model() - Train Loss: 1.72725(2.53770)
2023-01-22 22:22:29,857 - INFO - trainer.py:131 - train_model() - Grad: 99642.312
2023-01-22 22:22:29,857 - INFO - trainer.py:132 - train_model() - LR: 0.0000138881
2023-01-22 22:22:29,857 - INFO - trainer.py:133 - train_model() - Time: 0:03:40
2023-01-22 22:22:29,857 - INFO - trainer.py:134 - train_model() - **************************************************
2023-01-22 22:22:32,540 - INFO - trainer.py:190 - evaluate() - **************************************************
2023-01-22 22:22:32,540 - INFO - trainer.py:191 - evaluate() - Valid RECORD:
2023-01-22 22:22:32,540 - INFO - trainer.py:192 - evaluate() - Fold: 0
2023-01-22 22:22:32,540 - INFO - trainer.py:193 - evaluate() - Epoch: 003 [7/7 (100%)]
2023-01-22 22:22:32,540 - INFO - trainer.py:197 - evaluate() - Valid Loss: 2.11941(2.25637)
2023-01-22 22:22:32,541 - INFO - trainer.py:198 - evaluate() - Macro F1: 0.4137
2023-01-22 22:22:32,541 - INFO - trainer.py:199 - evaluate() - Time: 0:00:03
2023-01-22 22:22:32,541 - INFO - trainer.py:200 - evaluate() - **************************************************
2023-01-22 22:23:19,605 - INFO - trainer.py:123 - train_model() - **************************************************
2023-01-22 22:23:19,605 - INFO - trainer.py:124 - train_model() - TRAIN RECORD:
2023-01-22 22:23:19,605 - INFO - trainer.py:125 - train_model() - Fold: 0
2023-01-22 22:23:19,605 - INFO - trainer.py:126 - train_model() - Epoch: 004 [  61/109 ( 56%)]
2023-01-22 22:23:19,638 - INFO - trainer.py:130 - train_model() - Train Loss: 1.04884(2.34749)
2023-01-22 22:23:19,638 - INFO - trainer.py:131 - train_model() - Grad: 77921.109
2023-01-22 22:23:19,638 - INFO - trainer.py:132 - train_model() - LR: 0.0000137368
2023-01-22 22:23:19,638 - INFO - trainer.py:133 - train_model() - Time: 0:04:30
2023-01-22 22:23:19,638 - INFO - trainer.py:134 - train_model() - **************************************************
2023-01-22 22:23:22,334 - INFO - trainer.py:190 - evaluate() - **************************************************
2023-01-22 22:23:22,334 - INFO - trainer.py:191 - evaluate() - Valid RECORD:
2023-01-22 22:23:22,334 - INFO - trainer.py:192 - evaluate() - Fold: 0
2023-01-22 22:23:22,334 - INFO - trainer.py:193 - evaluate() - Epoch: 004 [7/7 (100%)]
2023-01-22 22:23:22,334 - INFO - trainer.py:197 - evaluate() - Valid Loss: 2.05826(2.14519)
2023-01-22 22:23:22,334 - INFO - trainer.py:198 - evaluate() - Macro F1: 0.4698
2023-01-22 22:23:22,334 - INFO - trainer.py:199 - evaluate() - Time: 0:00:03
2023-01-22 22:23:22,334 - INFO - trainer.py:200 - evaluate() - **************************************************
2023-01-22 22:24:00,760 - INFO - trainer.py:123 - train_model() - **************************************************
2023-01-22 22:24:00,761 - INFO - trainer.py:124 - train_model() - TRAIN RECORD:
2023-01-22 22:24:00,761 - INFO - trainer.py:125 - train_model() - Fold: 0
2023-01-22 22:24:00,761 - INFO - trainer.py:126 - train_model() - Epoch: 004 [ 109/109 (100%)]
2023-01-22 22:24:00,781 - INFO - trainer.py:130 - train_model() - Train Loss: 1.03889(2.22310)
2023-01-22 22:24:00,781 - INFO - trainer.py:131 - train_model() - Grad: 81543.031
2023-01-22 22:24:00,782 - INFO - trainer.py:132 - train_model() - LR: 0.0000135725
2023-01-22 22:24:00,782 - INFO - trainer.py:133 - train_model() - Time: 0:05:11
2023-01-22 22:24:00,782 - INFO - trainer.py:134 - train_model() - **************************************************
2023-01-22 22:24:03,477 - INFO - trainer.py:190 - evaluate() - **************************************************
2023-01-22 22:24:03,477 - INFO - trainer.py:191 - evaluate() - Valid RECORD:
2023-01-22 22:24:03,478 - INFO - trainer.py:192 - evaluate() - Fold: 0
2023-01-22 22:24:03,478 - INFO - trainer.py:193 - evaluate() - Epoch: 004 [7/7 (100%)]
2023-01-22 22:24:03,478 - INFO - trainer.py:197 - evaluate() - Valid Loss: 2.03996(2.12757)
2023-01-22 22:24:03,478 - INFO - trainer.py:198 - evaluate() - Macro F1: 0.4412
2023-01-22 22:24:03,478 - INFO - trainer.py:199 - evaluate() - Time: 0:00:03
2023-01-22 22:24:03,478 - INFO - trainer.py:200 - evaluate() - **************************************************
2023-01-22 22:24:03,478 - INFO - function_utils.py:301 - __call__() - EarlyStopping counter: 1 out of 6
2023-01-22 22:24:45,511 - INFO - trainer.py:123 - train_model() - **************************************************
2023-01-22 22:24:45,511 - INFO - trainer.py:124 - train_model() - TRAIN RECORD:
2023-01-22 22:24:45,511 - INFO - trainer.py:125 - train_model() - Fold: 0
2023-01-22 22:24:45,511 - INFO - trainer.py:126 - train_model() - Epoch: 005 [  61/109 ( 56%)]
2023-01-22 22:24:45,534 - INFO - trainer.py:130 - train_model() - Train Loss: 1.13593(2.09121)
2023-01-22 22:24:45,534 - INFO - trainer.py:131 - train_model() - Grad: 105423.117
2023-01-22 22:24:45,534 - INFO - trainer.py:132 - train_model() - LR: 0.0000133077
2023-01-22 22:24:45,534 - INFO - trainer.py:133 - train_model() - Time: 0:05:56
2023-01-22 22:24:45,534 - INFO - trainer.py:134 - train_model() - **************************************************
2023-01-22 22:24:48,228 - INFO - trainer.py:190 - evaluate() - **************************************************
2023-01-22 22:24:48,228 - INFO - trainer.py:191 - evaluate() - Valid RECORD:
2023-01-22 22:24:48,228 - INFO - trainer.py:192 - evaluate() - Fold: 0
2023-01-22 22:24:48,228 - INFO - trainer.py:193 - evaluate() - Epoch: 005 [7/7 (100%)]
2023-01-22 22:24:48,228 - INFO - trainer.py:197 - evaluate() - Valid Loss: 1.95641(2.15192)
2023-01-22 22:24:48,228 - INFO - trainer.py:198 - evaluate() - Macro F1: 0.4009
2023-01-22 22:24:48,228 - INFO - trainer.py:199 - evaluate() - Time: 0:00:03
2023-01-22 22:24:48,229 - INFO - trainer.py:200 - evaluate() - **************************************************
2023-01-22 22:24:48,229 - INFO - function_utils.py:301 - __call__() - EarlyStopping counter: 2 out of 6
2023-01-22 22:25:21,303 - INFO - trainer.py:123 - train_model() - **************************************************
2023-01-22 22:25:21,303 - INFO - trainer.py:124 - train_model() - TRAIN RECORD:
2023-01-22 22:25:21,303 - INFO - trainer.py:125 - train_model() - Fold: 0
2023-01-22 22:25:21,303 - INFO - trainer.py:126 - train_model() - Epoch: 005 [ 109/109 (100%)]
2023-01-22 22:25:21,325 - INFO - trainer.py:130 - train_model() - Train Loss: 0.66762(1.99582)
2023-01-22 22:25:21,326 - INFO - trainer.py:131 - train_model() - Grad: 66619.703
2023-01-22 22:25:21,326 - INFO - trainer.py:132 - train_model() - LR: 0.0000130570
2023-01-22 22:25:21,326 - INFO - trainer.py:133 - train_model() - Time: 0:06:32
2023-01-22 22:25:21,326 - INFO - trainer.py:134 - train_model() - **************************************************
2023-01-22 22:25:24,020 - INFO - trainer.py:190 - evaluate() - **************************************************
2023-01-22 22:25:24,020 - INFO - trainer.py:191 - evaluate() - Valid RECORD:
2023-01-22 22:25:24,021 - INFO - trainer.py:192 - evaluate() - Fold: 0
2023-01-22 22:25:24,021 - INFO - trainer.py:193 - evaluate() - Epoch: 005 [7/7 (100%)]
2023-01-22 22:25:24,021 - INFO - trainer.py:197 - evaluate() - Valid Loss: 1.89106(2.12885)
2023-01-22 22:25:24,021 - INFO - trainer.py:198 - evaluate() - Macro F1: 0.4428
2023-01-22 22:25:24,021 - INFO - trainer.py:199 - evaluate() - Time: 0:00:03
2023-01-22 22:25:24,021 - INFO - trainer.py:200 - evaluate() - **************************************************
2023-01-22 22:25:24,021 - INFO - function_utils.py:301 - __call__() - EarlyStopping counter: 3 out of 6
2023-01-22 22:26:06,167 - INFO - trainer.py:123 - train_model() - **************************************************
2023-01-22 22:26:06,167 - INFO - trainer.py:124 - train_model() - TRAIN RECORD:
2023-01-22 22:26:06,167 - INFO - trainer.py:125 - train_model() - Fold: 0
2023-01-22 22:26:06,167 - INFO - trainer.py:126 - train_model() - Epoch: 006 [  61/109 ( 56%)]
2023-01-22 22:26:06,189 - INFO - trainer.py:130 - train_model() - Train Loss: 0.79145(1.89514)
2023-01-22 22:26:06,189 - INFO - trainer.py:131 - train_model() - Grad: 59938.445
2023-01-22 22:26:06,189 - INFO - trainer.py:132 - train_model() - LR: 0.0000126869
2023-01-22 22:26:06,189 - INFO - trainer.py:133 - train_model() - Time: 0:07:17
2023-01-22 22:26:06,189 - INFO - trainer.py:134 - train_model() - **************************************************
2023-01-22 22:26:08,891 - INFO - trainer.py:190 - evaluate() - **************************************************
2023-01-22 22:26:08,891 - INFO - trainer.py:191 - evaluate() - Valid RECORD:
2023-01-22 22:26:08,891 - INFO - trainer.py:192 - evaluate() - Fold: 0
2023-01-22 22:26:08,891 - INFO - trainer.py:193 - evaluate() - Epoch: 006 [7/7 (100%)]
2023-01-22 22:26:08,892 - INFO - trainer.py:197 - evaluate() - Valid Loss: 1.87732(2.08963)
2023-01-22 22:26:08,892 - INFO - trainer.py:198 - evaluate() - Macro F1: 0.4395
2023-01-22 22:26:08,892 - INFO - trainer.py:199 - evaluate() - Time: 0:00:03
2023-01-22 22:26:08,892 - INFO - trainer.py:200 - evaluate() - **************************************************
2023-01-22 22:26:08,892 - INFO - function_utils.py:301 - __call__() - EarlyStopping counter: 4 out of 6
2023-01-22 22:26:42,274 - INFO - trainer.py:123 - train_model() - **************************************************
2023-01-22 22:26:42,275 - INFO - trainer.py:124 - train_model() - TRAIN RECORD:
2023-01-22 22:26:42,275 - INFO - trainer.py:125 - train_model() - Fold: 0
2023-01-22 22:26:42,275 - INFO - trainer.py:126 - train_model() - Epoch: 006 [ 109/109 (100%)]
2023-01-22 22:26:42,297 - INFO - trainer.py:130 - train_model() - Train Loss: 0.78136(1.82552)
2023-01-22 22:26:42,297 - INFO - trainer.py:131 - train_model() - Grad: 74306.797
2023-01-22 22:26:42,297 - INFO - trainer.py:132 - train_model() - LR: 0.0000123574
2023-01-22 22:26:42,297 - INFO - trainer.py:133 - train_model() - Time: 0:07:53
2023-01-22 22:26:42,297 - INFO - trainer.py:134 - train_model() - **************************************************
2023-01-22 22:26:44,999 - INFO - trainer.py:190 - evaluate() - **************************************************
2023-01-22 22:26:44,999 - INFO - trainer.py:191 - evaluate() - Valid RECORD:
2023-01-22 22:26:44,999 - INFO - trainer.py:192 - evaluate() - Fold: 0
2023-01-22 22:26:44,999 - INFO - trainer.py:193 - evaluate() - Epoch: 006 [7/7 (100%)]
2023-01-22 22:26:45,000 - INFO - trainer.py:197 - evaluate() - Valid Loss: 1.85071(2.09899)
2023-01-22 22:26:45,000 - INFO - trainer.py:198 - evaluate() - Macro F1: 0.4665
2023-01-22 22:26:45,000 - INFO - trainer.py:199 - evaluate() - Time: 0:00:03
2023-01-22 22:26:45,000 - INFO - trainer.py:200 - evaluate() - **************************************************
2023-01-22 22:26:45,000 - INFO - function_utils.py:301 - __call__() - EarlyStopping counter: 5 out of 6
2023-01-22 22:27:27,201 - INFO - trainer.py:123 - train_model() - **************************************************
2023-01-22 22:27:27,201 - INFO - trainer.py:124 - train_model() - TRAIN RECORD:
2023-01-22 22:27:27,201 - INFO - trainer.py:125 - train_model() - Fold: 0
2023-01-22 22:27:27,201 - INFO - trainer.py:126 - train_model() - Epoch: 007 [  61/109 ( 56%)]
2023-01-22 22:27:27,222 - INFO - trainer.py:130 - train_model() - Train Loss: 1.07477(1.74407)
2023-01-22 22:27:27,223 - INFO - trainer.py:131 - train_model() - Grad: 102912.750
2023-01-22 22:27:27,223 - INFO - trainer.py:132 - train_model() - LR: 0.0000118932
2023-01-22 22:27:27,223 - INFO - trainer.py:133 - train_model() - Time: 0:08:38
2023-01-22 22:27:27,223 - INFO - trainer.py:134 - train_model() - **************************************************
2023-01-22 22:27:29,924 - INFO - trainer.py:190 - evaluate() - **************************************************
2023-01-22 22:27:29,924 - INFO - trainer.py:191 - evaluate() - Valid RECORD:
2023-01-22 22:27:29,924 - INFO - trainer.py:192 - evaluate() - Fold: 0
2023-01-22 22:27:29,924 - INFO - trainer.py:193 - evaluate() - Epoch: 007 [7/7 (100%)]
2023-01-22 22:27:29,925 - INFO - trainer.py:197 - evaluate() - Valid Loss: 1.89861(2.12611)
2023-01-22 22:27:29,925 - INFO - trainer.py:198 - evaluate() - Macro F1: 0.4332
2023-01-22 22:27:29,925 - INFO - trainer.py:199 - evaluate() - Time: 0:00:03
2023-01-22 22:27:29,925 - INFO - trainer.py:200 - evaluate() - **************************************************
2023-01-22 22:27:29,925 - INFO - function_utils.py:301 - __call__() - EarlyStopping counter: 6 out of 6
2023-01-22 22:27:29,925 - INFO - trainer.py:144 - train_model() - ========== fold: 0 result ==========
2023-01-22 22:27:29,925 - INFO - trainer.py:145 - train_model() - {'[fold0] valid best score taskC': 0.46979268778872174}
2023-01-22 22:27:29,925 - INFO - trainer.py:148 - train_model() - {'[fold0] valid best score taskC': 0.46979268778872174}
2023-01-22 22:27:33,548 - INFO - trainer.py:53 - train_model() - ***** Running training *****
2023-01-22 22:27:33,548 - INFO - trainer.py:54 - train_model() -   Num Train examples = 109
2023-01-22 22:27:33,548 - INFO - trainer.py:55 - train_model() -   Num Valid examples = 7
2023-01-22 22:27:33,548 - INFO - trainer.py:56 - train_model() -   Num Epochs = 20
2023-01-22 22:27:33,548 - INFO - trainer.py:57 - train_model() -   Train batch size = 30
2023-01-22 22:27:33,548 - INFO - trainer.py:58 - train_model() -   Batch interval = 60
2023-01-22 22:27:33,548 - INFO - trainer.py:59 - train_model() -   Logging steps = 50
2023-01-22 22:27:33,549 - INFO - trainer.py:60 - train_model() -   Gradient Accumulation steps = 1
2023-01-22 22:27:53,106 - INFO - trainer.py:123 - train_model() - **************************************************
2023-01-22 22:27:53,106 - INFO - trainer.py:124 - train_model() - TRAIN RECORD:
2023-01-22 22:27:53,106 - INFO - trainer.py:125 - train_model() - Fold: 1
2023-01-22 22:27:53,106 - INFO - trainer.py:126 - train_model() - Epoch: 001 [  61/109 ( 56%)]
2023-01-22 22:27:53,127 - INFO - trainer.py:130 - train_model() - Train Loss: 3.07040(3.06141)
2023-01-22 22:27:53,127 - INFO - trainer.py:131 - train_model() - Grad: 90459.680
2023-01-22 22:27:53,127 - INFO - trainer.py:132 - train_model() - LR: 0.0000039159
2023-01-22 22:27:53,127 - INFO - trainer.py:133 - train_model() - Time: 0:00:20
2023-01-22 22:27:53,128 - INFO - trainer.py:134 - train_model() - **************************************************
2023-01-22 22:27:55,848 - INFO - trainer.py:190 - evaluate() - **************************************************
2023-01-22 22:27:55,848 - INFO - trainer.py:191 - evaluate() - Valid RECORD:
2023-01-22 22:27:55,848 - INFO - trainer.py:192 - evaluate() - Fold: 1
2023-01-22 22:27:55,848 - INFO - trainer.py:193 - evaluate() - Epoch: 001 [7/7 (100%)]
2023-01-22 22:27:55,848 - INFO - trainer.py:197 - evaluate() - Valid Loss: 3.22139(3.22172)
2023-01-22 22:27:55,848 - INFO - trainer.py:198 - evaluate() - Macro F1: 0.0497
2023-01-22 22:27:55,848 - INFO - trainer.py:199 - evaluate() - Time: 0:00:03
2023-01-22 22:27:55,848 - INFO - trainer.py:200 - evaluate() - **************************************************
2023-01-22 22:28:16,100 - INFO - trainer.py:123 - train_model() - **************************************************
2023-01-22 22:28:16,100 - INFO - trainer.py:124 - train_model() - TRAIN RECORD:
2023-01-22 22:28:16,100 - INFO - trainer.py:125 - train_model() - Fold: 1
2023-01-22 22:28:16,100 - INFO - trainer.py:126 - train_model() - Epoch: 001 [ 109/109 (100%)]
2023-01-22 22:28:16,121 - INFO - trainer.py:130 - train_model() - Train Loss: 3.02891(3.05149)
2023-01-22 22:28:16,122 - INFO - trainer.py:131 - train_model() - Grad: 72099.469
2023-01-22 22:28:16,122 - INFO - trainer.py:132 - train_model() - LR: 0.0000069972
2023-01-22 22:28:16,122 - INFO - trainer.py:133 - train_model() - Time: 0:00:43
2023-01-22 22:28:16,122 - INFO - trainer.py:134 - train_model() - **************************************************
2023-01-22 22:28:18,822 - INFO - trainer.py:190 - evaluate() - **************************************************
2023-01-22 22:28:18,822 - INFO - trainer.py:191 - evaluate() - Valid RECORD:
2023-01-22 22:28:18,823 - INFO - trainer.py:192 - evaluate() - Fold: 1
2023-01-22 22:28:18,823 - INFO - trainer.py:193 - evaluate() - Epoch: 001 [7/7 (100%)]
2023-01-22 22:28:18,823 - INFO - trainer.py:197 - evaluate() - Valid Loss: 3.26507(3.25937)
2023-01-22 22:28:18,823 - INFO - trainer.py:198 - evaluate() - Macro F1: 0.0372
2023-01-22 22:28:18,823 - INFO - trainer.py:199 - evaluate() - Time: 0:00:03
2023-01-22 22:28:18,823 - INFO - trainer.py:200 - evaluate() - **************************************************
2023-01-22 22:28:18,823 - INFO - function_utils.py:301 - __call__() - EarlyStopping counter: 1 out of 6
2023-01-22 22:29:01,016 - INFO - trainer.py:123 - train_model() - **************************************************
2023-01-22 22:29:01,016 - INFO - trainer.py:124 - train_model() - TRAIN RECORD:
2023-01-22 22:29:01,016 - INFO - trainer.py:125 - train_model() - Fold: 1
2023-01-22 22:29:01,017 - INFO - trainer.py:126 - train_model() - Epoch: 002 [  61/109 ( 56%)]
2023-01-22 22:29:01,038 - INFO - trainer.py:130 - train_model() - Train Loss: 2.81124(3.02240)
2023-01-22 22:29:01,038 - INFO - trainer.py:131 - train_model() - Grad: 64992.938
2023-01-22 22:29:01,038 - INFO - trainer.py:132 - train_model() - LR: 0.0000109131
2023-01-22 22:29:01,038 - INFO - trainer.py:133 - train_model() - Time: 0:01:27
2023-01-22 22:29:01,038 - INFO - trainer.py:134 - train_model() - **************************************************
2023-01-22 22:29:03,746 - INFO - trainer.py:190 - evaluate() - **************************************************
2023-01-22 22:29:03,746 - INFO - trainer.py:191 - evaluate() - Valid RECORD:
2023-01-22 22:29:03,747 - INFO - trainer.py:192 - evaluate() - Fold: 1
2023-01-22 22:29:03,747 - INFO - trainer.py:193 - evaluate() - Epoch: 002 [7/7 (100%)]
2023-01-22 22:29:03,747 - INFO - trainer.py:197 - evaluate() - Valid Loss: 3.21161(3.20160)
2023-01-22 22:29:03,747 - INFO - trainer.py:198 - evaluate() - Macro F1: 0.0691
2023-01-22 22:29:03,747 - INFO - trainer.py:199 - evaluate() - Time: 0:00:03
2023-01-22 22:29:03,747 - INFO - trainer.py:200 - evaluate() - **************************************************
2023-01-22 22:29:41,812 - INFO - trainer.py:123 - train_model() - **************************************************
2023-01-22 22:29:41,813 - INFO - trainer.py:124 - train_model() - TRAIN RECORD:
2023-01-22 22:29:41,813 - INFO - trainer.py:125 - train_model() - Fold: 1
2023-01-22 22:29:41,813 - INFO - trainer.py:126 - train_model() - Epoch: 002 [ 109/109 (100%)]
2023-01-22 22:29:41,845 - INFO - trainer.py:130 - train_model() - Train Loss: 2.29861(2.87826)
2023-01-22 22:29:41,845 - INFO - trainer.py:131 - train_model() - Grad: 103498.148
2023-01-22 22:29:41,845 - INFO - trainer.py:132 - train_model() - LR: 0.0000139944
2023-01-22 22:29:41,845 - INFO - trainer.py:133 - train_model() - Time: 0:02:08
2023-01-22 22:29:41,845 - INFO - trainer.py:134 - train_model() - **************************************************
2023-01-22 22:29:44,547 - INFO - trainer.py:190 - evaluate() - **************************************************
2023-01-22 22:29:44,547 - INFO - trainer.py:191 - evaluate() - Valid RECORD:
2023-01-22 22:29:44,548 - INFO - trainer.py:192 - evaluate() - Fold: 1
2023-01-22 22:29:44,548 - INFO - trainer.py:193 - evaluate() - Epoch: 002 [7/7 (100%)]
2023-01-22 22:29:44,548 - INFO - trainer.py:197 - evaluate() - Valid Loss: 2.64393(2.72950)
2023-01-22 22:29:44,548 - INFO - trainer.py:198 - evaluate() - Macro F1: 0.2188
2023-01-22 22:29:44,548 - INFO - trainer.py:199 - evaluate() - Time: 0:00:03
2023-01-22 22:29:44,548 - INFO - trainer.py:200 - evaluate() - **************************************************
2023-01-22 22:30:31,611 - INFO - trainer.py:123 - train_model() - **************************************************
2023-01-22 22:30:31,611 - INFO - trainer.py:124 - train_model() - TRAIN RECORD:
2023-01-22 22:30:31,611 - INFO - trainer.py:125 - train_model() - Fold: 1
2023-01-22 22:30:31,611 - INFO - trainer.py:126 - train_model() - Epoch: 003 [  61/109 ( 56%)]
2023-01-22 22:30:31,633 - INFO - trainer.py:130 - train_model() - Train Loss: 1.46620(2.64805)
2023-01-22 22:30:31,633 - INFO - trainer.py:131 - train_model() - Grad: 89376.242
2023-01-22 22:30:31,633 - INFO - trainer.py:132 - train_model() - LR: 0.0000139611
2023-01-22 22:30:31,633 - INFO - trainer.py:133 - train_model() - Time: 0:02:58
2023-01-22 22:30:31,633 - INFO - trainer.py:134 - train_model() - **************************************************
2023-01-22 22:30:34,336 - INFO - trainer.py:190 - evaluate() - **************************************************
2023-01-22 22:30:34,336 - INFO - trainer.py:191 - evaluate() - Valid RECORD:
2023-01-22 22:30:34,336 - INFO - trainer.py:192 - evaluate() - Fold: 1
2023-01-22 22:30:34,336 - INFO - trainer.py:193 - evaluate() - Epoch: 003 [7/7 (100%)]
2023-01-22 22:30:34,336 - INFO - trainer.py:197 - evaluate() - Valid Loss: 2.23061(2.40516)
2023-01-22 22:30:34,336 - INFO - trainer.py:198 - evaluate() - Macro F1: 0.3564
2023-01-22 22:30:34,337 - INFO - trainer.py:199 - evaluate() - Time: 0:00:03
2023-01-22 22:30:34,337 - INFO - trainer.py:200 - evaluate() - **************************************************
2023-01-22 22:31:12,763 - INFO - trainer.py:123 - train_model() - **************************************************
2023-01-22 22:31:12,763 - INFO - trainer.py:124 - train_model() - TRAIN RECORD:
2023-01-22 22:31:12,763 - INFO - trainer.py:125 - train_model() - Fold: 1
2023-01-22 22:31:12,763 - INFO - trainer.py:126 - train_model() - Epoch: 003 [ 109/109 (100%)]
2023-01-22 22:31:12,787 - INFO - trainer.py:130 - train_model() - Train Loss: 1.60108(2.47510)
2023-01-22 22:31:12,787 - INFO - trainer.py:131 - train_model() - Grad: 125194.133
2023-01-22 22:31:12,787 - INFO - trainer.py:132 - train_model() - LR: 0.0000138881
2023-01-22 22:31:12,787 - INFO - trainer.py:133 - train_model() - Time: 0:03:39
2023-01-22 22:31:12,787 - INFO - trainer.py:134 - train_model() - **************************************************
2023-01-22 22:31:15,491 - INFO - trainer.py:190 - evaluate() - **************************************************
2023-01-22 22:31:15,491 - INFO - trainer.py:191 - evaluate() - Valid RECORD:
2023-01-22 22:31:15,491 - INFO - trainer.py:192 - evaluate() - Fold: 1
2023-01-22 22:31:15,491 - INFO - trainer.py:193 - evaluate() - Epoch: 003 [7/7 (100%)]
2023-01-22 22:31:15,491 - INFO - trainer.py:197 - evaluate() - Valid Loss: 2.12496(2.30016)
2023-01-22 22:31:15,491 - INFO - trainer.py:198 - evaluate() - Macro F1: 0.4014
2023-01-22 22:31:15,491 - INFO - trainer.py:199 - evaluate() - Time: 0:00:03
2023-01-22 22:31:15,491 - INFO - trainer.py:200 - evaluate() - **************************************************
2023-01-22 22:32:02,828 - INFO - trainer.py:123 - train_model() - **************************************************
2023-01-22 22:32:02,828 - INFO - trainer.py:124 - train_model() - TRAIN RECORD:
2023-01-22 22:32:02,828 - INFO - trainer.py:125 - train_model() - Fold: 1
2023-01-22 22:32:02,828 - INFO - trainer.py:126 - train_model() - Epoch: 004 [  61/109 ( 56%)]
2023-01-22 22:32:02,862 - INFO - trainer.py:130 - train_model() - Train Loss: 1.39783(2.28905)
2023-01-22 22:32:02,862 - INFO - trainer.py:131 - train_model() - Grad: 131779.500
2023-01-22 22:32:02,862 - INFO - trainer.py:132 - train_model() - LR: 0.0000137368
2023-01-22 22:32:02,862 - INFO - trainer.py:133 - train_model() - Time: 0:04:29
2023-01-22 22:32:02,862 - INFO - trainer.py:134 - train_model() - **************************************************
2023-01-22 22:32:05,574 - INFO - trainer.py:190 - evaluate() - **************************************************
2023-01-22 22:32:05,574 - INFO - trainer.py:191 - evaluate() - Valid RECORD:
2023-01-22 22:32:05,575 - INFO - trainer.py:192 - evaluate() - Fold: 1
2023-01-22 22:32:05,575 - INFO - trainer.py:193 - evaluate() - Epoch: 004 [7/7 (100%)]
2023-01-22 22:32:05,575 - INFO - trainer.py:197 - evaluate() - Valid Loss: 1.98942(2.23445)
2023-01-22 22:32:05,575 - INFO - trainer.py:198 - evaluate() - Macro F1: 0.4364
2023-01-22 22:32:05,575 - INFO - trainer.py:199 - evaluate() - Time: 0:00:03
2023-01-22 22:32:05,575 - INFO - trainer.py:200 - evaluate() - **************************************************
2023-01-22 22:32:43,910 - INFO - trainer.py:123 - train_model() - **************************************************
2023-01-22 22:32:43,910 - INFO - trainer.py:124 - train_model() - TRAIN RECORD:
2023-01-22 22:32:43,910 - INFO - trainer.py:125 - train_model() - Fold: 1
2023-01-22 22:32:43,910 - INFO - trainer.py:126 - train_model() - Epoch: 004 [ 109/109 (100%)]
2023-01-22 22:32:43,933 - INFO - trainer.py:130 - train_model() - Train Loss: 1.20112(2.17304)
2023-01-22 22:32:43,933 - INFO - trainer.py:131 - train_model() - Grad: 80299.398
2023-01-22 22:32:43,933 - INFO - trainer.py:132 - train_model() - LR: 0.0000135725
2023-01-22 22:32:43,933 - INFO - trainer.py:133 - train_model() - Time: 0:05:10
2023-01-22 22:32:43,933 - INFO - trainer.py:134 - train_model() - **************************************************
2023-01-22 22:32:46,647 - INFO - trainer.py:190 - evaluate() - **************************************************
2023-01-22 22:32:46,647 - INFO - trainer.py:191 - evaluate() - Valid RECORD:
2023-01-22 22:32:46,647 - INFO - trainer.py:192 - evaluate() - Fold: 1
2023-01-22 22:32:46,647 - INFO - trainer.py:193 - evaluate() - Epoch: 004 [7/7 (100%)]
2023-01-22 22:32:46,647 - INFO - trainer.py:197 - evaluate() - Valid Loss: 2.00521(2.18365)
2023-01-22 22:32:46,647 - INFO - trainer.py:198 - evaluate() - Macro F1: 0.4693
2023-01-22 22:32:46,648 - INFO - trainer.py:199 - evaluate() - Time: 0:00:03
2023-01-22 22:32:46,648 - INFO - trainer.py:200 - evaluate() - **************************************************
2023-01-22 22:33:34,019 - INFO - trainer.py:123 - train_model() - **************************************************
2023-01-22 22:33:34,019 - INFO - trainer.py:124 - train_model() - TRAIN RECORD:
2023-01-22 22:33:34,019 - INFO - trainer.py:125 - train_model() - Fold: 1
2023-01-22 22:33:34,019 - INFO - trainer.py:126 - train_model() - Epoch: 005 [  61/109 ( 56%)]
2023-01-22 22:33:34,043 - INFO - trainer.py:130 - train_model() - Train Loss: 1.20440(2.04747)
2023-01-22 22:33:34,044 - INFO - trainer.py:131 - train_model() - Grad: 123350.773
2023-01-22 22:33:34,044 - INFO - trainer.py:132 - train_model() - LR: 0.0000133077
2023-01-22 22:33:34,044 - INFO - trainer.py:133 - train_model() - Time: 0:06:00
2023-01-22 22:33:34,044 - INFO - trainer.py:134 - train_model() - **************************************************
2023-01-22 22:33:36,752 - INFO - trainer.py:190 - evaluate() - **************************************************
2023-01-22 22:33:36,752 - INFO - trainer.py:191 - evaluate() - Valid RECORD:
2023-01-22 22:33:36,752 - INFO - trainer.py:192 - evaluate() - Fold: 1
2023-01-22 22:33:36,752 - INFO - trainer.py:193 - evaluate() - Epoch: 005 [7/7 (100%)]
2023-01-22 22:33:36,752 - INFO - trainer.py:197 - evaluate() - Valid Loss: 2.05991(2.19928)
2023-01-22 22:33:36,752 - INFO - trainer.py:198 - evaluate() - Macro F1: 0.4523
2023-01-22 22:33:36,753 - INFO - trainer.py:199 - evaluate() - Time: 0:00:03
2023-01-22 22:33:36,753 - INFO - trainer.py:200 - evaluate() - **************************************************
2023-01-22 22:33:36,753 - INFO - function_utils.py:301 - __call__() - EarlyStopping counter: 1 out of 6
2023-01-22 22:34:09,960 - INFO - trainer.py:123 - train_model() - **************************************************
2023-01-22 22:34:09,960 - INFO - trainer.py:124 - train_model() - TRAIN RECORD:
2023-01-22 22:34:09,960 - INFO - trainer.py:125 - train_model() - Fold: 1
2023-01-22 22:34:09,961 - INFO - trainer.py:126 - train_model() - Epoch: 005 [ 109/109 (100%)]
2023-01-22 22:34:09,982 - INFO - trainer.py:130 - train_model() - Train Loss: 1.23469(1.95992)
2023-01-22 22:34:09,983 - INFO - trainer.py:131 - train_model() - Grad: 134484.031
2023-01-22 22:34:09,983 - INFO - trainer.py:132 - train_model() - LR: 0.0000130570
2023-01-22 22:34:09,983 - INFO - trainer.py:133 - train_model() - Time: 0:06:36
2023-01-22 22:34:09,983 - INFO - trainer.py:134 - train_model() - **************************************************
2023-01-22 22:34:12,692 - INFO - trainer.py:190 - evaluate() - **************************************************
2023-01-22 22:34:12,692 - INFO - trainer.py:191 - evaluate() - Valid RECORD:
2023-01-22 22:34:12,693 - INFO - trainer.py:192 - evaluate() - Fold: 1
2023-01-22 22:34:12,693 - INFO - trainer.py:193 - evaluate() - Epoch: 005 [7/7 (100%)]
2023-01-22 22:34:12,693 - INFO - trainer.py:197 - evaluate() - Valid Loss: 1.96040(2.14901)
2023-01-22 22:34:12,693 - INFO - trainer.py:198 - evaluate() - Macro F1: 0.4671
2023-01-22 22:34:12,693 - INFO - trainer.py:199 - evaluate() - Time: 0:00:03
2023-01-22 22:34:12,693 - INFO - trainer.py:200 - evaluate() - **************************************************
2023-01-22 22:34:12,693 - INFO - function_utils.py:301 - __call__() - EarlyStopping counter: 2 out of 6
2023-01-22 22:34:54,886 - INFO - trainer.py:123 - train_model() - **************************************************
2023-01-22 22:34:54,886 - INFO - trainer.py:124 - train_model() - TRAIN RECORD:
2023-01-22 22:34:54,886 - INFO - trainer.py:125 - train_model() - Fold: 1
2023-01-22 22:34:54,886 - INFO - trainer.py:126 - train_model() - Epoch: 006 [  61/109 ( 56%)]
2023-01-22 22:34:54,906 - INFO - trainer.py:130 - train_model() - Train Loss: 0.84015(1.86087)
2023-01-22 22:34:54,907 - INFO - trainer.py:131 - train_model() - Grad: 102536.656
2023-01-22 22:34:54,907 - INFO - trainer.py:132 - train_model() - LR: 0.0000126869
2023-01-22 22:34:54,907 - INFO - trainer.py:133 - train_model() - Time: 0:07:21
2023-01-22 22:34:54,907 - INFO - trainer.py:134 - train_model() - **************************************************
2023-01-22 22:34:57,618 - INFO - trainer.py:190 - evaluate() - **************************************************
2023-01-22 22:34:57,618 - INFO - trainer.py:191 - evaluate() - Valid RECORD:
2023-01-22 22:34:57,618 - INFO - trainer.py:192 - evaluate() - Fold: 1
2023-01-22 22:34:57,618 - INFO - trainer.py:193 - evaluate() - Epoch: 006 [7/7 (100%)]
2023-01-22 22:34:57,618 - INFO - trainer.py:197 - evaluate() - Valid Loss: 1.92903(2.12569)
2023-01-22 22:34:57,618 - INFO - trainer.py:198 - evaluate() - Macro F1: 0.4875
2023-01-22 22:34:57,619 - INFO - trainer.py:199 - evaluate() - Time: 0:00:03
2023-01-22 22:34:57,619 - INFO - trainer.py:200 - evaluate() - **************************************************
2023-01-22 22:35:35,841 - INFO - trainer.py:123 - train_model() - **************************************************
2023-01-22 22:35:35,841 - INFO - trainer.py:124 - train_model() - TRAIN RECORD:
2023-01-22 22:35:35,841 - INFO - trainer.py:125 - train_model() - Fold: 1
2023-01-22 22:35:35,841 - INFO - trainer.py:126 - train_model() - Epoch: 006 [ 109/109 (100%)]
2023-01-22 22:35:35,862 - INFO - trainer.py:130 - train_model() - Train Loss: 0.58659(1.79467)
2023-01-22 22:35:35,862 - INFO - trainer.py:131 - train_model() - Grad: 72539.484
2023-01-22 22:35:35,862 - INFO - trainer.py:132 - train_model() - LR: 0.0000123574
2023-01-22 22:35:35,862 - INFO - trainer.py:133 - train_model() - Time: 0:08:02
2023-01-22 22:35:35,863 - INFO - trainer.py:134 - train_model() - **************************************************
2023-01-22 22:35:38,564 - INFO - trainer.py:190 - evaluate() - **************************************************
2023-01-22 22:35:38,564 - INFO - trainer.py:191 - evaluate() - Valid RECORD:
2023-01-22 22:35:38,564 - INFO - trainer.py:192 - evaluate() - Fold: 1
2023-01-22 22:35:38,564 - INFO - trainer.py:193 - evaluate() - Epoch: 006 [7/7 (100%)]
2023-01-22 22:35:38,564 - INFO - trainer.py:197 - evaluate() - Valid Loss: 1.96005(2.10681)
2023-01-22 22:35:38,564 - INFO - trainer.py:198 - evaluate() - Macro F1: 0.4714
2023-01-22 22:35:38,564 - INFO - trainer.py:199 - evaluate() - Time: 0:00:03
2023-01-22 22:35:38,564 - INFO - trainer.py:200 - evaluate() - **************************************************
2023-01-22 22:35:38,564 - INFO - function_utils.py:301 - __call__() - EarlyStopping counter: 1 out of 6
2023-01-22 22:36:20,729 - INFO - trainer.py:123 - train_model() - **************************************************
2023-01-22 22:36:20,729 - INFO - trainer.py:124 - train_model() - TRAIN RECORD:
2023-01-22 22:36:20,729 - INFO - trainer.py:125 - train_model() - Fold: 1
2023-01-22 22:36:20,729 - INFO - trainer.py:126 - train_model() - Epoch: 007 [  61/109 ( 56%)]
2023-01-22 22:36:20,751 - INFO - trainer.py:130 - train_model() - Train Loss: 0.64571(1.71513)
2023-01-22 22:36:20,751 - INFO - trainer.py:131 - train_model() - Grad: 59365.254
2023-01-22 22:36:20,751 - INFO - trainer.py:132 - train_model() - LR: 0.0000118932
2023-01-22 22:36:20,751 - INFO - trainer.py:133 - train_model() - Time: 0:08:47
2023-01-22 22:36:20,751 - INFO - trainer.py:134 - train_model() - **************************************************
2023-01-22 22:36:23,461 - INFO - trainer.py:190 - evaluate() - **************************************************
2023-01-22 22:36:23,461 - INFO - trainer.py:191 - evaluate() - Valid RECORD:
2023-01-22 22:36:23,461 - INFO - trainer.py:192 - evaluate() - Fold: 1
2023-01-22 22:36:23,461 - INFO - trainer.py:193 - evaluate() - Epoch: 007 [7/7 (100%)]
2023-01-22 22:36:23,461 - INFO - trainer.py:197 - evaluate() - Valid Loss: 1.95301(2.12499)
2023-01-22 22:36:23,461 - INFO - trainer.py:198 - evaluate() - Macro F1: 0.4894
2023-01-22 22:36:23,461 - INFO - trainer.py:199 - evaluate() - Time: 0:00:03
2023-01-22 22:36:23,461 - INFO - trainer.py:200 - evaluate() - **************************************************
2023-01-22 22:37:01,831 - INFO - trainer.py:123 - train_model() - **************************************************
2023-01-22 22:37:01,831 - INFO - trainer.py:124 - train_model() - TRAIN RECORD:
2023-01-22 22:37:01,831 - INFO - trainer.py:125 - train_model() - Fold: 1
2023-01-22 22:37:01,831 - INFO - trainer.py:126 - train_model() - Epoch: 007 [ 109/109 (100%)]
2023-01-22 22:37:01,861 - INFO - trainer.py:130 - train_model() - Train Loss: 1.13551(1.66054)
2023-01-22 22:37:01,862 - INFO - trainer.py:131 - train_model() - Grad: 130587.805
2023-01-22 22:37:01,862 - INFO - trainer.py:132 - train_model() - LR: 0.0000114949
2023-01-22 22:37:01,862 - INFO - trainer.py:133 - train_model() - Time: 0:09:28
2023-01-22 22:37:01,862 - INFO - trainer.py:134 - train_model() - **************************************************
2023-01-22 22:37:04,569 - INFO - trainer.py:190 - evaluate() - **************************************************
2023-01-22 22:37:04,569 - INFO - trainer.py:191 - evaluate() - Valid RECORD:
2023-01-22 22:37:04,569 - INFO - trainer.py:192 - evaluate() - Fold: 1
2023-01-22 22:37:04,569 - INFO - trainer.py:193 - evaluate() - Epoch: 007 [7/7 (100%)]
2023-01-22 22:37:04,569 - INFO - trainer.py:197 - evaluate() - Valid Loss: 1.97918(2.13287)
2023-01-22 22:37:04,569 - INFO - trainer.py:198 - evaluate() - Macro F1: 0.4922
2023-01-22 22:37:04,569 - INFO - trainer.py:199 - evaluate() - Time: 0:00:03
2023-01-22 22:37:04,569 - INFO - trainer.py:200 - evaluate() - **************************************************
2023-01-22 22:37:51,755 - INFO - trainer.py:123 - train_model() - **************************************************
2023-01-22 22:37:51,755 - INFO - trainer.py:124 - train_model() - TRAIN RECORD:
2023-01-22 22:37:51,755 - INFO - trainer.py:125 - train_model() - Fold: 1
2023-01-22 22:37:51,755 - INFO - trainer.py:126 - train_model() - Epoch: 008 [  61/109 ( 56%)]
2023-01-22 22:37:51,777 - INFO - trainer.py:130 - train_model() - Train Loss: 0.62894(1.59978)
2023-01-22 22:37:51,777 - INFO - trainer.py:131 - train_model() - Grad: 56794.418
2023-01-22 22:37:51,777 - INFO - trainer.py:132 - train_model() - LR: 0.0000109508
2023-01-22 22:37:51,777 - INFO - trainer.py:133 - train_model() - Time: 0:10:18
2023-01-22 22:37:51,777 - INFO - trainer.py:134 - train_model() - **************************************************
2023-01-22 22:37:54,483 - INFO - trainer.py:190 - evaluate() - **************************************************
2023-01-22 22:37:54,483 - INFO - trainer.py:191 - evaluate() - Valid RECORD:
2023-01-22 22:37:54,483 - INFO - trainer.py:192 - evaluate() - Fold: 1
2023-01-22 22:37:54,483 - INFO - trainer.py:193 - evaluate() - Epoch: 008 [7/7 (100%)]
2023-01-22 22:37:54,483 - INFO - trainer.py:197 - evaluate() - Valid Loss: 1.94656(2.11591)
2023-01-22 22:37:54,483 - INFO - trainer.py:198 - evaluate() - Macro F1: 0.4668
2023-01-22 22:37:54,483 - INFO - trainer.py:199 - evaluate() - Time: 0:00:03
2023-01-22 22:37:54,483 - INFO - trainer.py:200 - evaluate() - **************************************************
2023-01-22 22:37:54,483 - INFO - function_utils.py:301 - __call__() - EarlyStopping counter: 1 out of 6
2023-01-22 22:38:27,657 - INFO - trainer.py:123 - train_model() - **************************************************
2023-01-22 22:38:27,657 - INFO - trainer.py:124 - train_model() - TRAIN RECORD:
2023-01-22 22:38:27,657 - INFO - trainer.py:125 - train_model() - Fold: 1
2023-01-22 22:38:27,657 - INFO - trainer.py:126 - train_model() - Epoch: 008 [ 109/109 (100%)]
2023-01-22 22:38:27,680 - INFO - trainer.py:130 - train_model() - Train Loss: 0.73179(1.55153)
2023-01-22 22:38:27,680 - INFO - trainer.py:131 - train_model() - Grad: 103126.773
2023-01-22 22:38:27,680 - INFO - trainer.py:132 - train_model() - LR: 0.0000104958
2023-01-22 22:38:27,680 - INFO - trainer.py:133 - train_model() - Time: 0:10:54
2023-01-22 22:38:27,680 - INFO - trainer.py:134 - train_model() - **************************************************
2023-01-22 22:38:30,388 - INFO - trainer.py:190 - evaluate() - **************************************************
2023-01-22 22:38:30,388 - INFO - trainer.py:191 - evaluate() - Valid RECORD:
2023-01-22 22:38:30,388 - INFO - trainer.py:192 - evaluate() - Fold: 1
2023-01-22 22:38:30,388 - INFO - trainer.py:193 - evaluate() - Epoch: 008 [7/7 (100%)]
2023-01-22 22:38:30,388 - INFO - trainer.py:197 - evaluate() - Valid Loss: 2.08801(2.20742)
2023-01-22 22:38:30,388 - INFO - trainer.py:198 - evaluate() - Macro F1: 0.4570
2023-01-22 22:38:30,388 - INFO - trainer.py:199 - evaluate() - Time: 0:00:03
2023-01-22 22:38:30,388 - INFO - trainer.py:200 - evaluate() - **************************************************
2023-01-22 22:38:30,388 - INFO - function_utils.py:301 - __call__() - EarlyStopping counter: 2 out of 6
2023-01-22 22:39:12,618 - INFO - trainer.py:123 - train_model() - **************************************************
2023-01-22 22:39:12,618 - INFO - trainer.py:124 - train_model() - TRAIN RECORD:
2023-01-22 22:39:12,618 - INFO - trainer.py:125 - train_model() - Fold: 1
2023-01-22 22:39:12,618 - INFO - trainer.py:126 - train_model() - Epoch: 009 [  61/109 ( 56%)]
2023-01-22 22:39:12,644 - INFO - trainer.py:130 - train_model() - Train Loss: 0.77438(1.49920)
2023-01-22 22:39:12,644 - INFO - trainer.py:131 - train_model() - Grad: 92797.406
2023-01-22 22:39:12,644 - INFO - trainer.py:132 - train_model() - LR: 0.0000098882
2023-01-22 22:39:12,644 - INFO - trainer.py:133 - train_model() - Time: 0:11:39
2023-01-22 22:39:12,644 - INFO - trainer.py:134 - train_model() - **************************************************
2023-01-22 22:39:15,355 - INFO - trainer.py:190 - evaluate() - **************************************************
2023-01-22 22:39:15,355 - INFO - trainer.py:191 - evaluate() - Valid RECORD:
2023-01-22 22:39:15,355 - INFO - trainer.py:192 - evaluate() - Fold: 1
2023-01-22 22:39:15,355 - INFO - trainer.py:193 - evaluate() - Epoch: 009 [7/7 (100%)]
2023-01-22 22:39:15,356 - INFO - trainer.py:197 - evaluate() - Valid Loss: 2.12793(2.19893)
2023-01-22 22:39:15,356 - INFO - trainer.py:198 - evaluate() - Macro F1: 0.4709
2023-01-22 22:39:15,356 - INFO - trainer.py:199 - evaluate() - Time: 0:00:03
2023-01-22 22:39:15,356 - INFO - trainer.py:200 - evaluate() - **************************************************
2023-01-22 22:39:15,356 - INFO - function_utils.py:301 - __call__() - EarlyStopping counter: 3 out of 6
2023-01-22 22:39:48,519 - INFO - trainer.py:123 - train_model() - **************************************************
2023-01-22 22:39:48,519 - INFO - trainer.py:124 - train_model() - TRAIN RECORD:
2023-01-22 22:39:48,519 - INFO - trainer.py:125 - train_model() - Fold: 1
2023-01-22 22:39:48,519 - INFO - trainer.py:126 - train_model() - Epoch: 009 [ 109/109 (100%)]
2023-01-22 22:39:48,539 - INFO - trainer.py:130 - train_model() - Train Loss: 0.59518(1.45758)
2023-01-22 22:39:48,539 - INFO - trainer.py:131 - train_model() - Grad: 73618.969
2023-01-22 22:39:48,539 - INFO - trainer.py:132 - train_model() - LR: 0.0000093904
2023-01-22 22:39:48,539 - INFO - trainer.py:133 - train_model() - Time: 0:12:15
2023-01-22 22:39:48,539 - INFO - trainer.py:134 - train_model() - **************************************************
2023-01-22 22:39:51,248 - INFO - trainer.py:190 - evaluate() - **************************************************
2023-01-22 22:39:51,248 - INFO - trainer.py:191 - evaluate() - Valid RECORD:
2023-01-22 22:39:51,248 - INFO - trainer.py:192 - evaluate() - Fold: 1
2023-01-22 22:39:51,248 - INFO - trainer.py:193 - evaluate() - Epoch: 009 [7/7 (100%)]
2023-01-22 22:39:51,249 - INFO - trainer.py:197 - evaluate() - Valid Loss: 2.07837(2.19459)
2023-01-22 22:39:51,249 - INFO - trainer.py:198 - evaluate() - Macro F1: 0.4605
2023-01-22 22:39:51,249 - INFO - trainer.py:199 - evaluate() - Time: 0:00:03
2023-01-22 22:39:51,249 - INFO - trainer.py:200 - evaluate() - **************************************************
2023-01-22 22:39:51,249 - INFO - function_utils.py:301 - __call__() - EarlyStopping counter: 4 out of 6
2023-01-22 22:40:33,400 - INFO - trainer.py:123 - train_model() - **************************************************
2023-01-22 22:40:33,400 - INFO - trainer.py:124 - train_model() - TRAIN RECORD:
2023-01-22 22:40:33,400 - INFO - trainer.py:125 - train_model() - Fold: 1
2023-01-22 22:40:33,400 - INFO - trainer.py:126 - train_model() - Epoch: 010 [  61/109 ( 56%)]
2023-01-22 22:40:33,421 - INFO - trainer.py:130 - train_model() - Train Loss: 0.60421(1.41151)
2023-01-22 22:40:33,421 - INFO - trainer.py:131 - train_model() - Grad: 43357.637
2023-01-22 22:40:33,421 - INFO - trainer.py:132 - train_model() - LR: 0.0000087378
2023-01-22 22:40:33,421 - INFO - trainer.py:133 - train_model() - Time: 0:13:00
2023-01-22 22:40:33,421 - INFO - trainer.py:134 - train_model() - **************************************************
2023-01-22 22:40:36,126 - INFO - trainer.py:190 - evaluate() - **************************************************
2023-01-22 22:40:36,126 - INFO - trainer.py:191 - evaluate() - Valid RECORD:
2023-01-22 22:40:36,127 - INFO - trainer.py:192 - evaluate() - Fold: 1
2023-01-22 22:40:36,127 - INFO - trainer.py:193 - evaluate() - Epoch: 010 [7/7 (100%)]
2023-01-22 22:40:36,127 - INFO - trainer.py:197 - evaluate() - Valid Loss: 2.08578(2.19815)
2023-01-22 22:40:36,127 - INFO - trainer.py:198 - evaluate() - Macro F1: 0.4695
2023-01-22 22:40:36,127 - INFO - trainer.py:199 - evaluate() - Time: 0:00:03
2023-01-22 22:40:36,127 - INFO - trainer.py:200 - evaluate() - **************************************************
2023-01-22 22:40:36,127 - INFO - function_utils.py:301 - __call__() - EarlyStopping counter: 5 out of 6
2023-01-22 22:41:09,387 - INFO - trainer.py:123 - train_model() - **************************************************
2023-01-22 22:41:09,387 - INFO - trainer.py:124 - train_model() - TRAIN RECORD:
2023-01-22 22:41:09,388 - INFO - trainer.py:125 - train_model() - Fold: 1
2023-01-22 22:41:09,388 - INFO - trainer.py:126 - train_model() - Epoch: 010 [ 109/109 (100%)]
2023-01-22 22:41:09,408 - INFO - trainer.py:130 - train_model() - Train Loss: 0.57562(1.37712)
2023-01-22 22:41:09,408 - INFO - trainer.py:131 - train_model() - Grad: 63778.914
2023-01-22 22:41:09,408 - INFO - trainer.py:132 - train_model() - LR: 0.0000082123
2023-01-22 22:41:09,408 - INFO - trainer.py:133 - train_model() - Time: 0:13:36
2023-01-22 22:41:09,408 - INFO - trainer.py:134 - train_model() - **************************************************
2023-01-22 22:41:12,113 - INFO - trainer.py:190 - evaluate() - **************************************************
2023-01-22 22:41:12,114 - INFO - trainer.py:191 - evaluate() - Valid RECORD:
2023-01-22 22:41:12,114 - INFO - trainer.py:192 - evaluate() - Fold: 1
2023-01-22 22:41:12,114 - INFO - trainer.py:193 - evaluate() - Epoch: 010 [7/7 (100%)]
2023-01-22 22:41:12,114 - INFO - trainer.py:197 - evaluate() - Valid Loss: 2.12705(2.21265)
2023-01-22 22:41:12,114 - INFO - trainer.py:198 - evaluate() - Macro F1: 0.4670
2023-01-22 22:41:12,114 - INFO - trainer.py:199 - evaluate() - Time: 0:00:03
2023-01-22 22:41:12,114 - INFO - trainer.py:200 - evaluate() - **************************************************
2023-01-22 22:41:12,114 - INFO - function_utils.py:301 - __call__() - EarlyStopping counter: 6 out of 6
2023-01-22 22:41:12,114 - INFO - trainer.py:144 - train_model() - ========== fold: 1 result ==========
2023-01-22 22:41:12,114 - INFO - trainer.py:145 - train_model() - {'[fold1] valid best score taskC': 0.492230071065508}
2023-01-22 22:41:12,114 - INFO - trainer.py:148 - train_model() - {'[fold1] valid best score taskC': 0.492230071065508}
2023-01-22 22:41:15,759 - INFO - trainer.py:53 - train_model() - ***** Running training *****
2023-01-22 22:41:15,759 - INFO - trainer.py:54 - train_model() -   Num Train examples = 109
2023-01-22 22:41:15,760 - INFO - trainer.py:55 - train_model() -   Num Valid examples = 7
2023-01-22 22:41:15,760 - INFO - trainer.py:56 - train_model() -   Num Epochs = 20
2023-01-22 22:41:15,760 - INFO - trainer.py:57 - train_model() -   Train batch size = 30
2023-01-22 22:41:15,760 - INFO - trainer.py:58 - train_model() -   Batch interval = 60
2023-01-22 22:41:15,760 - INFO - trainer.py:59 - train_model() -   Logging steps = 50
2023-01-22 22:41:15,760 - INFO - trainer.py:60 - train_model() -   Gradient Accumulation steps = 1
2023-01-22 22:41:35,240 - INFO - trainer.py:123 - train_model() - **************************************************
2023-01-22 22:41:35,240 - INFO - trainer.py:124 - train_model() - TRAIN RECORD:
2023-01-22 22:41:35,240 - INFO - trainer.py:125 - train_model() - Fold: 2
2023-01-22 22:41:35,240 - INFO - trainer.py:126 - train_model() - Epoch: 001 [  61/109 ( 56%)]
2023-01-22 22:41:35,263 - INFO - trainer.py:130 - train_model() - Train Loss: 3.06230(3.13491)
2023-01-22 22:41:35,263 - INFO - trainer.py:131 - train_model() - Grad: 52017.234
2023-01-22 22:41:35,264 - INFO - trainer.py:132 - train_model() - LR: 0.0000039159
2023-01-22 22:41:35,264 - INFO - trainer.py:133 - train_model() - Time: 0:00:19
2023-01-22 22:41:35,264 - INFO - trainer.py:134 - train_model() - **************************************************
2023-01-22 22:41:37,982 - INFO - trainer.py:190 - evaluate() - **************************************************
2023-01-22 22:41:37,982 - INFO - trainer.py:191 - evaluate() - Valid RECORD:
2023-01-22 22:41:37,982 - INFO - trainer.py:192 - evaluate() - Fold: 2
2023-01-22 22:41:37,982 - INFO - trainer.py:193 - evaluate() - Epoch: 001 [7/7 (100%)]
2023-01-22 22:41:37,982 - INFO - trainer.py:197 - evaluate() - Valid Loss: 3.42582(3.48844)
2023-01-22 22:41:37,983 - INFO - trainer.py:198 - evaluate() - Macro F1: 0.0037
2023-01-22 22:41:37,983 - INFO - trainer.py:199 - evaluate() - Time: 0:00:03
2023-01-22 22:41:37,983 - INFO - trainer.py:200 - evaluate() - **************************************************
2023-01-22 22:41:57,999 - INFO - trainer.py:123 - train_model() - **************************************************
2023-01-22 22:41:58,000 - INFO - trainer.py:124 - train_model() - TRAIN RECORD:
2023-01-22 22:41:58,000 - INFO - trainer.py:125 - train_model() - Fold: 2
2023-01-22 22:41:58,000 - INFO - trainer.py:126 - train_model() - Epoch: 001 [ 109/109 (100%)]
2023-01-22 22:41:58,017 - INFO - trainer.py:130 - train_model() - Train Loss: 3.08215(3.12311)
2023-01-22 22:41:58,017 - INFO - trainer.py:131 - train_model() - Grad: 76800.570
2023-01-22 22:41:58,018 - INFO - trainer.py:132 - train_model() - LR: 0.0000069972
2023-01-22 22:41:58,018 - INFO - trainer.py:133 - train_model() - Time: 0:00:42
2023-01-22 22:41:58,018 - INFO - trainer.py:134 - train_model() - **************************************************
2023-01-22 22:42:00,717 - INFO - trainer.py:190 - evaluate() - **************************************************
2023-01-22 22:42:00,717 - INFO - trainer.py:191 - evaluate() - Valid RECORD:
2023-01-22 22:42:00,717 - INFO - trainer.py:192 - evaluate() - Fold: 2
2023-01-22 22:42:00,717 - INFO - trainer.py:193 - evaluate() - Epoch: 001 [7/7 (100%)]
2023-01-22 22:42:00,717 - INFO - trainer.py:197 - evaluate() - Valid Loss: 3.37075(3.40322)
2023-01-22 22:42:00,718 - INFO - trainer.py:198 - evaluate() - Macro F1: 0.0087
2023-01-22 22:42:00,718 - INFO - trainer.py:199 - evaluate() - Time: 0:00:03
2023-01-22 22:42:00,718 - INFO - trainer.py:200 - evaluate() - **************************************************
2023-01-22 22:42:48,329 - INFO - trainer.py:123 - train_model() - **************************************************
2023-01-22 22:42:48,329 - INFO - trainer.py:124 - train_model() - TRAIN RECORD:
2023-01-22 22:42:48,329 - INFO - trainer.py:125 - train_model() - Fold: 2
2023-01-22 22:42:48,329 - INFO - trainer.py:126 - train_model() - Epoch: 002 [  61/109 ( 56%)]
2023-01-22 22:42:48,351 - INFO - trainer.py:130 - train_model() - Train Loss: 2.91533(3.07618)
2023-01-22 22:42:48,351 - INFO - trainer.py:131 - train_model() - Grad: 61024.703
2023-01-22 22:42:48,351 - INFO - trainer.py:132 - train_model() - LR: 0.0000109131
2023-01-22 22:42:48,351 - INFO - trainer.py:133 - train_model() - Time: 0:01:33
2023-01-22 22:42:48,351 - INFO - trainer.py:134 - train_model() - **************************************************
2023-01-22 22:42:51,056 - INFO - trainer.py:190 - evaluate() - **************************************************
2023-01-22 22:42:51,056 - INFO - trainer.py:191 - evaluate() - Valid RECORD:
2023-01-22 22:42:51,056 - INFO - trainer.py:192 - evaluate() - Fold: 2
2023-01-22 22:42:51,056 - INFO - trainer.py:193 - evaluate() - Epoch: 002 [7/7 (100%)]
2023-01-22 22:42:51,056 - INFO - trainer.py:197 - evaluate() - Valid Loss: 3.29164(3.26150)
2023-01-22 22:42:51,056 - INFO - trainer.py:198 - evaluate() - Macro F1: 0.0368
2023-01-22 22:42:51,056 - INFO - trainer.py:199 - evaluate() - Time: 0:00:03
2023-01-22 22:42:51,056 - INFO - trainer.py:200 - evaluate() - **************************************************
2023-01-22 22:43:29,165 - INFO - trainer.py:123 - train_model() - **************************************************
2023-01-22 22:43:29,165 - INFO - trainer.py:124 - train_model() - TRAIN RECORD:
2023-01-22 22:43:29,165 - INFO - trainer.py:125 - train_model() - Fold: 2
2023-01-22 22:43:29,165 - INFO - trainer.py:126 - train_model() - Epoch: 002 [ 109/109 (100%)]
2023-01-22 22:43:29,199 - INFO - trainer.py:130 - train_model() - Train Loss: 2.06796(2.94325)
2023-01-22 22:43:29,199 - INFO - trainer.py:131 - train_model() - Grad: 86613.664
2023-01-22 22:43:29,199 - INFO - trainer.py:132 - train_model() - LR: 0.0000139944
2023-01-22 22:43:29,199 - INFO - trainer.py:133 - train_model() - Time: 0:02:13
2023-01-22 22:43:29,199 - INFO - trainer.py:134 - train_model() - **************************************************
2023-01-22 22:43:31,908 - INFO - trainer.py:190 - evaluate() - **************************************************
2023-01-22 22:43:31,909 - INFO - trainer.py:191 - evaluate() - Valid RECORD:
2023-01-22 22:43:31,909 - INFO - trainer.py:192 - evaluate() - Fold: 2
2023-01-22 22:43:31,909 - INFO - trainer.py:193 - evaluate() - Epoch: 002 [7/7 (100%)]
2023-01-22 22:43:31,909 - INFO - trainer.py:197 - evaluate() - Valid Loss: 2.84618(2.76259)
2023-01-22 22:43:31,909 - INFO - trainer.py:198 - evaluate() - Macro F1: 0.1987
2023-01-22 22:43:31,909 - INFO - trainer.py:199 - evaluate() - Time: 0:00:03
2023-01-22 22:43:31,909 - INFO - trainer.py:200 - evaluate() - **************************************************
2023-01-22 22:44:19,170 - INFO - trainer.py:123 - train_model() - **************************************************
2023-01-22 22:44:19,170 - INFO - trainer.py:124 - train_model() - TRAIN RECORD:
2023-01-22 22:44:19,170 - INFO - trainer.py:125 - train_model() - Fold: 2
2023-01-22 22:44:19,170 - INFO - trainer.py:126 - train_model() - Epoch: 003 [  61/109 ( 56%)]
2023-01-22 22:44:19,191 - INFO - trainer.py:130 - train_model() - Train Loss: 1.69494(2.70641)
2023-01-22 22:44:19,191 - INFO - trainer.py:131 - train_model() - Grad: 111470.492
2023-01-22 22:44:19,191 - INFO - trainer.py:132 - train_model() - LR: 0.0000139611
2023-01-22 22:44:19,191 - INFO - trainer.py:133 - train_model() - Time: 0:03:03
2023-01-22 22:44:19,191 - INFO - trainer.py:134 - train_model() - **************************************************
2023-01-22 22:44:21,898 - INFO - trainer.py:190 - evaluate() - **************************************************
2023-01-22 22:44:21,898 - INFO - trainer.py:191 - evaluate() - Valid RECORD:
2023-01-22 22:44:21,898 - INFO - trainer.py:192 - evaluate() - Fold: 2
2023-01-22 22:44:21,898 - INFO - trainer.py:193 - evaluate() - Epoch: 003 [7/7 (100%)]
2023-01-22 22:44:21,898 - INFO - trainer.py:197 - evaluate() - Valid Loss: 2.51341(2.43569)
2023-01-22 22:44:21,898 - INFO - trainer.py:198 - evaluate() - Macro F1: 0.3351
2023-01-22 22:44:21,898 - INFO - trainer.py:199 - evaluate() - Time: 0:00:03
2023-01-22 22:44:21,898 - INFO - trainer.py:200 - evaluate() - **************************************************
2023-01-22 22:45:00,496 - INFO - trainer.py:123 - train_model() - **************************************************
2023-01-22 22:45:00,496 - INFO - trainer.py:124 - train_model() - TRAIN RECORD:
2023-01-22 22:45:00,496 - INFO - trainer.py:125 - train_model() - Fold: 2
2023-01-22 22:45:00,496 - INFO - trainer.py:126 - train_model() - Epoch: 003 [ 109/109 (100%)]
2023-01-22 22:45:00,518 - INFO - trainer.py:130 - train_model() - Train Loss: 1.19860(2.53922)
2023-01-22 22:45:00,519 - INFO - trainer.py:131 - train_model() - Grad: 74967.047
2023-01-22 22:45:00,519 - INFO - trainer.py:132 - train_model() - LR: 0.0000138881
2023-01-22 22:45:00,519 - INFO - trainer.py:133 - train_model() - Time: 0:03:45
2023-01-22 22:45:00,519 - INFO - trainer.py:134 - train_model() - **************************************************
2023-01-22 22:45:03,223 - INFO - trainer.py:190 - evaluate() - **************************************************
2023-01-22 22:45:03,223 - INFO - trainer.py:191 - evaluate() - Valid RECORD:
2023-01-22 22:45:03,224 - INFO - trainer.py:192 - evaluate() - Fold: 2
2023-01-22 22:45:03,224 - INFO - trainer.py:193 - evaluate() - Epoch: 003 [7/7 (100%)]
2023-01-22 22:45:03,224 - INFO - trainer.py:197 - evaluate() - Valid Loss: 2.31105(2.25208)
2023-01-22 22:45:03,224 - INFO - trainer.py:198 - evaluate() - Macro F1: 0.4013
2023-01-22 22:45:03,224 - INFO - trainer.py:199 - evaluate() - Time: 0:00:03
2023-01-22 22:45:03,224 - INFO - trainer.py:200 - evaluate() - **************************************************
2023-01-22 22:45:50,353 - INFO - trainer.py:123 - train_model() - **************************************************
2023-01-22 22:45:50,353 - INFO - trainer.py:124 - train_model() - TRAIN RECORD:
2023-01-22 22:45:50,353 - INFO - trainer.py:125 - train_model() - Fold: 2
2023-01-22 22:45:50,354 - INFO - trainer.py:126 - train_model() - Epoch: 004 [  61/109 ( 56%)]
2023-01-22 22:45:50,387 - INFO - trainer.py:130 - train_model() - Train Loss: 1.25660(2.35351)
2023-01-22 22:45:50,387 - INFO - trainer.py:131 - train_model() - Grad: 100733.812
2023-01-22 22:45:50,387 - INFO - trainer.py:132 - train_model() - LR: 0.0000137368
2023-01-22 22:45:50,387 - INFO - trainer.py:133 - train_model() - Time: 0:04:35
2023-01-22 22:45:50,387 - INFO - trainer.py:134 - train_model() - **************************************************
2023-01-22 22:45:53,100 - INFO - trainer.py:190 - evaluate() - **************************************************
2023-01-22 22:45:53,100 - INFO - trainer.py:191 - evaluate() - Valid RECORD:
2023-01-22 22:45:53,100 - INFO - trainer.py:192 - evaluate() - Fold: 2
2023-01-22 22:45:53,100 - INFO - trainer.py:193 - evaluate() - Epoch: 004 [7/7 (100%)]
2023-01-22 22:45:53,100 - INFO - trainer.py:197 - evaluate() - Valid Loss: 2.25896(2.18795)
2023-01-22 22:45:53,100 - INFO - trainer.py:198 - evaluate() - Macro F1: 0.4588
2023-01-22 22:45:53,100 - INFO - trainer.py:199 - evaluate() - Time: 0:00:03
2023-01-22 22:45:53,100 - INFO - trainer.py:200 - evaluate() - **************************************************
2023-01-22 22:46:31,637 - INFO - trainer.py:123 - train_model() - **************************************************
2023-01-22 22:46:31,637 - INFO - trainer.py:124 - train_model() - TRAIN RECORD:
2023-01-22 22:46:31,637 - INFO - trainer.py:125 - train_model() - Fold: 2
2023-01-22 22:46:31,637 - INFO - trainer.py:126 - train_model() - Epoch: 004 [ 109/109 (100%)]
2023-01-22 22:46:31,658 - INFO - trainer.py:130 - train_model() - Train Loss: 1.48014(2.22674)
2023-01-22 22:46:31,658 - INFO - trainer.py:131 - train_model() - Grad: 113897.820
2023-01-22 22:46:31,658 - INFO - trainer.py:132 - train_model() - LR: 0.0000135725
2023-01-22 22:46:31,659 - INFO - trainer.py:133 - train_model() - Time: 0:05:16
2023-01-22 22:46:31,659 - INFO - trainer.py:134 - train_model() - **************************************************
2023-01-22 22:46:34,367 - INFO - trainer.py:190 - evaluate() - **************************************************
2023-01-22 22:46:34,367 - INFO - trainer.py:191 - evaluate() - Valid RECORD:
2023-01-22 22:46:34,367 - INFO - trainer.py:192 - evaluate() - Fold: 2
2023-01-22 22:46:34,367 - INFO - trainer.py:193 - evaluate() - Epoch: 004 [7/7 (100%)]
2023-01-22 22:46:34,367 - INFO - trainer.py:197 - evaluate() - Valid Loss: 2.23529(2.17938)
2023-01-22 22:46:34,367 - INFO - trainer.py:198 - evaluate() - Macro F1: 0.4631
2023-01-22 22:46:34,367 - INFO - trainer.py:199 - evaluate() - Time: 0:00:03
2023-01-22 22:46:34,368 - INFO - trainer.py:200 - evaluate() - **************************************************
2023-01-22 22:47:21,683 - INFO - trainer.py:123 - train_model() - **************************************************
2023-01-22 22:47:21,683 - INFO - trainer.py:124 - train_model() - TRAIN RECORD:
2023-01-22 22:47:21,683 - INFO - trainer.py:125 - train_model() - Fold: 2
2023-01-22 22:47:21,683 - INFO - trainer.py:126 - train_model() - Epoch: 005 [  61/109 ( 56%)]
2023-01-22 22:47:21,704 - INFO - trainer.py:130 - train_model() - Train Loss: 1.29749(2.09346)
2023-01-22 22:47:21,704 - INFO - trainer.py:131 - train_model() - Grad: 121889.609
2023-01-22 22:47:21,704 - INFO - trainer.py:132 - train_model() - LR: 0.0000133077
2023-01-22 22:47:21,704 - INFO - trainer.py:133 - train_model() - Time: 0:06:06
2023-01-22 22:47:21,704 - INFO - trainer.py:134 - train_model() - **************************************************
2023-01-22 22:47:24,428 - INFO - trainer.py:190 - evaluate() - **************************************************
2023-01-22 22:47:24,428 - INFO - trainer.py:191 - evaluate() - Valid RECORD:
2023-01-22 22:47:24,428 - INFO - trainer.py:192 - evaluate() - Fold: 2
2023-01-22 22:47:24,428 - INFO - trainer.py:193 - evaluate() - Epoch: 005 [7/7 (100%)]
2023-01-22 22:47:24,429 - INFO - trainer.py:197 - evaluate() - Valid Loss: 2.10884(2.09024)
2023-01-22 22:47:24,429 - INFO - trainer.py:198 - evaluate() - Macro F1: 0.4734
2023-01-22 22:47:24,429 - INFO - trainer.py:199 - evaluate() - Time: 0:00:03
2023-01-22 22:47:24,429 - INFO - trainer.py:200 - evaluate() - **************************************************
2023-01-22 22:48:02,528 - INFO - trainer.py:123 - train_model() - **************************************************
2023-01-22 22:48:02,528 - INFO - trainer.py:124 - train_model() - TRAIN RECORD:
2023-01-22 22:48:02,528 - INFO - trainer.py:125 - train_model() - Fold: 2
2023-01-22 22:48:02,528 - INFO - trainer.py:126 - train_model() - Epoch: 005 [ 109/109 (100%)]
2023-01-22 22:48:02,550 - INFO - trainer.py:130 - train_model() - Train Loss: 1.03631(2.00071)
2023-01-22 22:48:02,550 - INFO - trainer.py:131 - train_model() - Grad: 107952.359
2023-01-22 22:48:02,551 - INFO - trainer.py:132 - train_model() - LR: 0.0000130570
2023-01-22 22:48:02,551 - INFO - trainer.py:133 - train_model() - Time: 0:06:47
2023-01-22 22:48:02,551 - INFO - trainer.py:134 - train_model() - **************************************************
2023-01-22 22:48:05,257 - INFO - trainer.py:190 - evaluate() - **************************************************
2023-01-22 22:48:05,257 - INFO - trainer.py:191 - evaluate() - Valid RECORD:
2023-01-22 22:48:05,257 - INFO - trainer.py:192 - evaluate() - Fold: 2
2023-01-22 22:48:05,257 - INFO - trainer.py:193 - evaluate() - Epoch: 005 [7/7 (100%)]
2023-01-22 22:48:05,257 - INFO - trainer.py:197 - evaluate() - Valid Loss: 2.19069(2.10235)
2023-01-22 22:48:05,257 - INFO - trainer.py:198 - evaluate() - Macro F1: 0.4577
2023-01-22 22:48:05,257 - INFO - trainer.py:199 - evaluate() - Time: 0:00:03
2023-01-22 22:48:05,257 - INFO - trainer.py:200 - evaluate() - **************************************************
2023-01-22 22:48:05,258 - INFO - function_utils.py:301 - __call__() - EarlyStopping counter: 1 out of 6
2023-01-22 22:48:47,559 - INFO - trainer.py:123 - train_model() - **************************************************
2023-01-22 22:48:47,559 - INFO - trainer.py:124 - train_model() - TRAIN RECORD:
2023-01-22 22:48:47,559 - INFO - trainer.py:125 - train_model() - Fold: 2
2023-01-22 22:48:47,559 - INFO - trainer.py:126 - train_model() - Epoch: 006 [  61/109 ( 56%)]
2023-01-22 22:48:47,582 - INFO - trainer.py:130 - train_model() - Train Loss: 0.96318(1.89327)
2023-01-22 22:48:47,582 - INFO - trainer.py:131 - train_model() - Grad: 87075.234
2023-01-22 22:48:47,582 - INFO - trainer.py:132 - train_model() - LR: 0.0000126869
2023-01-22 22:48:47,583 - INFO - trainer.py:133 - train_model() - Time: 0:07:32
2023-01-22 22:48:47,583 - INFO - trainer.py:134 - train_model() - **************************************************
2023-01-22 22:48:50,296 - INFO - trainer.py:190 - evaluate() - **************************************************
2023-01-22 22:48:50,296 - INFO - trainer.py:191 - evaluate() - Valid RECORD:
2023-01-22 22:48:50,296 - INFO - trainer.py:192 - evaluate() - Fold: 2
2023-01-22 22:48:50,296 - INFO - trainer.py:193 - evaluate() - Epoch: 006 [7/7 (100%)]
2023-01-22 22:48:50,296 - INFO - trainer.py:197 - evaluate() - Valid Loss: 2.13643(2.10162)
2023-01-22 22:48:50,296 - INFO - trainer.py:198 - evaluate() - Macro F1: 0.4579
2023-01-22 22:48:50,296 - INFO - trainer.py:199 - evaluate() - Time: 0:00:03
2023-01-22 22:48:50,296 - INFO - trainer.py:200 - evaluate() - **************************************************
2023-01-22 22:48:50,296 - INFO - function_utils.py:301 - __call__() - EarlyStopping counter: 2 out of 6
2023-01-22 22:49:23,506 - INFO - trainer.py:123 - train_model() - **************************************************
2023-01-22 22:49:23,506 - INFO - trainer.py:124 - train_model() - TRAIN RECORD:
2023-01-22 22:49:23,506 - INFO - trainer.py:125 - train_model() - Fold: 2
2023-01-22 22:49:23,506 - INFO - trainer.py:126 - train_model() - Epoch: 006 [ 109/109 (100%)]
2023-01-22 22:49:23,527 - INFO - trainer.py:130 - train_model() - Train Loss: 0.69575(1.82029)
2023-01-22 22:49:23,527 - INFO - trainer.py:131 - train_model() - Grad: 61933.926
2023-01-22 22:49:23,527 - INFO - trainer.py:132 - train_model() - LR: 0.0000123574
2023-01-22 22:49:23,527 - INFO - trainer.py:133 - train_model() - Time: 0:08:08
2023-01-22 22:49:23,527 - INFO - trainer.py:134 - train_model() - **************************************************
2023-01-22 22:49:26,240 - INFO - trainer.py:190 - evaluate() - **************************************************
2023-01-22 22:49:26,240 - INFO - trainer.py:191 - evaluate() - Valid RECORD:
2023-01-22 22:49:26,240 - INFO - trainer.py:192 - evaluate() - Fold: 2
2023-01-22 22:49:26,240 - INFO - trainer.py:193 - evaluate() - Epoch: 006 [7/7 (100%)]
2023-01-22 22:49:26,241 - INFO - trainer.py:197 - evaluate() - Valid Loss: 2.16300(2.11602)
2023-01-22 22:49:26,241 - INFO - trainer.py:198 - evaluate() - Macro F1: 0.4628
2023-01-22 22:49:26,241 - INFO - trainer.py:199 - evaluate() - Time: 0:00:03
2023-01-22 22:49:26,241 - INFO - trainer.py:200 - evaluate() - **************************************************
2023-01-22 22:49:26,241 - INFO - function_utils.py:301 - __call__() - EarlyStopping counter: 3 out of 6
2023-01-22 22:50:08,508 - INFO - trainer.py:123 - train_model() - **************************************************
2023-01-22 22:50:08,508 - INFO - trainer.py:124 - train_model() - TRAIN RECORD:
2023-01-22 22:50:08,508 - INFO - trainer.py:125 - train_model() - Fold: 2
2023-01-22 22:50:08,508 - INFO - trainer.py:126 - train_model() - Epoch: 007 [  61/109 ( 56%)]
2023-01-22 22:50:08,530 - INFO - trainer.py:130 - train_model() - Train Loss: 0.87831(1.73814)
2023-01-22 22:50:08,530 - INFO - trainer.py:131 - train_model() - Grad: 70171.281
2023-01-22 22:50:08,530 - INFO - trainer.py:132 - train_model() - LR: 0.0000118932
2023-01-22 22:50:08,530 - INFO - trainer.py:133 - train_model() - Time: 0:08:53
2023-01-22 22:50:08,530 - INFO - trainer.py:134 - train_model() - **************************************************
2023-01-22 22:50:11,245 - INFO - trainer.py:190 - evaluate() - **************************************************
2023-01-22 22:50:11,246 - INFO - trainer.py:191 - evaluate() - Valid RECORD:
2023-01-22 22:50:11,246 - INFO - trainer.py:192 - evaluate() - Fold: 2
2023-01-22 22:50:11,246 - INFO - trainer.py:193 - evaluate() - Epoch: 007 [7/7 (100%)]
2023-01-22 22:50:11,246 - INFO - trainer.py:197 - evaluate() - Valid Loss: 2.14587(2.09999)
2023-01-22 22:50:11,246 - INFO - trainer.py:198 - evaluate() - Macro F1: 0.4511
2023-01-22 22:50:11,246 - INFO - trainer.py:199 - evaluate() - Time: 0:00:03
2023-01-22 22:50:11,246 - INFO - trainer.py:200 - evaluate() - **************************************************
2023-01-22 22:50:11,246 - INFO - function_utils.py:301 - __call__() - EarlyStopping counter: 4 out of 6
2023-01-22 22:50:44,450 - INFO - trainer.py:123 - train_model() - **************************************************
2023-01-22 22:50:44,450 - INFO - trainer.py:124 - train_model() - TRAIN RECORD:
2023-01-22 22:50:44,450 - INFO - trainer.py:125 - train_model() - Fold: 2
2023-01-22 22:50:44,450 - INFO - trainer.py:126 - train_model() - Epoch: 007 [ 109/109 (100%)]
2023-01-22 22:50:44,481 - INFO - trainer.py:130 - train_model() - Train Loss: 0.70386(1.68065)
2023-01-22 22:50:44,481 - INFO - trainer.py:131 - train_model() - Grad: 61887.516
2023-01-22 22:50:44,481 - INFO - trainer.py:132 - train_model() - LR: 0.0000114949
2023-01-22 22:50:44,481 - INFO - trainer.py:133 - train_model() - Time: 0:09:29
2023-01-22 22:50:44,481 - INFO - trainer.py:134 - train_model() - **************************************************
2023-01-22 22:50:47,196 - INFO - trainer.py:190 - evaluate() - **************************************************
2023-01-22 22:50:47,197 - INFO - trainer.py:191 - evaluate() - Valid RECORD:
2023-01-22 22:50:47,197 - INFO - trainer.py:192 - evaluate() - Fold: 2
2023-01-22 22:50:47,197 - INFO - trainer.py:193 - evaluate() - Epoch: 007 [7/7 (100%)]
2023-01-22 22:50:47,197 - INFO - trainer.py:197 - evaluate() - Valid Loss: 2.18446(2.09502)
2023-01-22 22:50:47,197 - INFO - trainer.py:198 - evaluate() - Macro F1: 0.4611
2023-01-22 22:50:47,197 - INFO - trainer.py:199 - evaluate() - Time: 0:00:03
2023-01-22 22:50:47,197 - INFO - trainer.py:200 - evaluate() - **************************************************
2023-01-22 22:50:47,197 - INFO - function_utils.py:301 - __call__() - EarlyStopping counter: 5 out of 6
2023-01-22 22:51:29,423 - INFO - trainer.py:123 - train_model() - **************************************************
2023-01-22 22:51:29,423 - INFO - trainer.py:124 - train_model() - TRAIN RECORD:
2023-01-22 22:51:29,423 - INFO - trainer.py:125 - train_model() - Fold: 2
2023-01-22 22:51:29,423 - INFO - trainer.py:126 - train_model() - Epoch: 008 [  61/109 ( 56%)]
2023-01-22 22:51:29,444 - INFO - trainer.py:130 - train_model() - Train Loss: 0.71582(1.61496)
2023-01-22 22:51:29,445 - INFO - trainer.py:131 - train_model() - Grad: 57146.754
2023-01-22 22:51:29,445 - INFO - trainer.py:132 - train_model() - LR: 0.0000109508
2023-01-22 22:51:29,445 - INFO - trainer.py:133 - train_model() - Time: 0:10:14
2023-01-22 22:51:29,445 - INFO - trainer.py:134 - train_model() - **************************************************
2023-01-22 22:51:32,155 - INFO - trainer.py:190 - evaluate() - **************************************************
2023-01-22 22:51:32,155 - INFO - trainer.py:191 - evaluate() - Valid RECORD:
2023-01-22 22:51:32,156 - INFO - trainer.py:192 - evaluate() - Fold: 2
2023-01-22 22:51:32,156 - INFO - trainer.py:193 - evaluate() - Epoch: 008 [7/7 (100%)]
2023-01-22 22:51:32,156 - INFO - trainer.py:197 - evaluate() - Valid Loss: 2.21836(2.12463)
2023-01-22 22:51:32,156 - INFO - trainer.py:198 - evaluate() - Macro F1: 0.4716
2023-01-22 22:51:32,156 - INFO - trainer.py:199 - evaluate() - Time: 0:00:03
2023-01-22 22:51:32,156 - INFO - trainer.py:200 - evaluate() - **************************************************
2023-01-22 22:51:32,156 - INFO - function_utils.py:301 - __call__() - EarlyStopping counter: 6 out of 6
2023-01-22 22:51:32,156 - INFO - trainer.py:144 - train_model() - ========== fold: 2 result ==========
2023-01-22 22:51:32,156 - INFO - trainer.py:145 - train_model() - {'[fold2] valid best score taskC': 0.47338500777740267}
2023-01-22 22:51:32,156 - INFO - trainer.py:148 - train_model() - {'[fold2] valid best score taskC': 0.47338500777740267}
2023-01-22 22:51:35,790 - INFO - trainer.py:53 - train_model() - ***** Running training *****
2023-01-22 22:51:35,790 - INFO - trainer.py:54 - train_model() -   Num Train examples = 110
2023-01-22 22:51:35,790 - INFO - trainer.py:55 - train_model() -   Num Valid examples = 7
2023-01-22 22:51:35,790 - INFO - trainer.py:56 - train_model() -   Num Epochs = 20
2023-01-22 22:51:35,790 - INFO - trainer.py:57 - train_model() -   Train batch size = 30
2023-01-22 22:51:35,791 - INFO - trainer.py:58 - train_model() -   Batch interval = 60
2023-01-22 22:51:35,791 - INFO - trainer.py:59 - train_model() -   Logging steps = 50
2023-01-22 22:51:35,791 - INFO - trainer.py:60 - train_model() -   Gradient Accumulation steps = 1
2023-01-22 22:51:55,312 - INFO - trainer.py:123 - train_model() - **************************************************
2023-01-22 22:51:55,313 - INFO - trainer.py:124 - train_model() - TRAIN RECORD:
2023-01-22 22:51:55,313 - INFO - trainer.py:125 - train_model() - Fold: 3
2023-01-22 22:51:55,313 - INFO - trainer.py:126 - train_model() - Epoch: 001 [  61/110 ( 55%)]
2023-01-22 22:51:55,333 - INFO - trainer.py:130 - train_model() - Train Loss: 3.06572(3.09051)
2023-01-22 22:51:55,333 - INFO - trainer.py:131 - train_model() - Grad: 77376.883
2023-01-22 22:51:55,333 - INFO - trainer.py:132 - train_model() - LR: 0.0000038803
2023-01-22 22:51:55,333 - INFO - trainer.py:133 - train_model() - Time: 0:00:20
2023-01-22 22:51:55,333 - INFO - trainer.py:134 - train_model() - **************************************************
2023-01-22 22:51:58,052 - INFO - trainer.py:190 - evaluate() - **************************************************
2023-01-22 22:51:58,052 - INFO - trainer.py:191 - evaluate() - Valid RECORD:
2023-01-22 22:51:58,052 - INFO - trainer.py:192 - evaluate() - Fold: 3
2023-01-22 22:51:58,052 - INFO - trainer.py:193 - evaluate() - Epoch: 001 [7/7 (100%)]
2023-01-22 22:51:58,052 - INFO - trainer.py:197 - evaluate() - Valid Loss: 3.37465(3.44030)
2023-01-22 22:51:58,052 - INFO - trainer.py:198 - evaluate() - Macro F1: 0.0052
2023-01-22 22:51:58,052 - INFO - trainer.py:199 - evaluate() - Time: 0:00:03
2023-01-22 22:51:58,052 - INFO - trainer.py:200 - evaluate() - **************************************************
2023-01-22 22:52:18,606 - INFO - trainer.py:123 - train_model() - **************************************************
2023-01-22 22:52:18,606 - INFO - trainer.py:124 - train_model() - TRAIN RECORD:
2023-01-22 22:52:18,606 - INFO - trainer.py:125 - train_model() - Fold: 3
2023-01-22 22:52:18,606 - INFO - trainer.py:126 - train_model() - Epoch: 001 [ 110/110 (100%)]
2023-01-22 22:52:18,628 - INFO - trainer.py:130 - train_model() - Train Loss: 2.33789(3.06749)
2023-01-22 22:52:18,628 - INFO - trainer.py:131 - train_model() - Grad: 126008.336
2023-01-22 22:52:18,628 - INFO - trainer.py:132 - train_model() - LR: 0.0000069972
2023-01-22 22:52:18,628 - INFO - trainer.py:133 - train_model() - Time: 0:00:43
2023-01-22 22:52:18,628 - INFO - trainer.py:134 - train_model() - **************************************************
2023-01-22 22:52:21,325 - INFO - trainer.py:190 - evaluate() - **************************************************
2023-01-22 22:52:21,325 - INFO - trainer.py:191 - evaluate() - Valid RECORD:
2023-01-22 22:52:21,325 - INFO - trainer.py:192 - evaluate() - Fold: 3
2023-01-22 22:52:21,325 - INFO - trainer.py:193 - evaluate() - Epoch: 001 [7/7 (100%)]
2023-01-22 22:52:21,325 - INFO - trainer.py:197 - evaluate() - Valid Loss: 3.34984(3.40707)
2023-01-22 22:52:21,326 - INFO - trainer.py:198 - evaluate() - Macro F1: 0.0025
2023-01-22 22:52:21,326 - INFO - trainer.py:199 - evaluate() - Time: 0:00:03
2023-01-22 22:52:21,326 - INFO - trainer.py:200 - evaluate() - **************************************************
2023-01-22 22:52:21,326 - INFO - function_utils.py:301 - __call__() - EarlyStopping counter: 1 out of 6
2023-01-22 22:53:03,592 - INFO - trainer.py:123 - train_model() - **************************************************
2023-01-22 22:53:03,592 - INFO - trainer.py:124 - train_model() - TRAIN RECORD:
2023-01-22 22:53:03,592 - INFO - trainer.py:125 - train_model() - Fold: 3
2023-01-22 22:53:03,592 - INFO - trainer.py:126 - train_model() - Epoch: 002 [  61/110 ( 55%)]
2023-01-22 22:53:03,614 - INFO - trainer.py:130 - train_model() - Train Loss: 2.88508(3.04360)
2023-01-22 22:53:03,615 - INFO - trainer.py:131 - train_model() - Grad: 67173.602
2023-01-22 22:53:03,615 - INFO - trainer.py:132 - train_model() - LR: 0.0000108775
2023-01-22 22:53:03,615 - INFO - trainer.py:133 - train_model() - Time: 0:01:28
2023-01-22 22:53:03,615 - INFO - trainer.py:134 - train_model() - **************************************************
2023-01-22 22:53:06,323 - INFO - trainer.py:190 - evaluate() - **************************************************
2023-01-22 22:53:06,323 - INFO - trainer.py:191 - evaluate() - Valid RECORD:
2023-01-22 22:53:06,323 - INFO - trainer.py:192 - evaluate() - Fold: 3
2023-01-22 22:53:06,323 - INFO - trainer.py:193 - evaluate() - Epoch: 002 [7/7 (100%)]
2023-01-22 22:53:06,323 - INFO - trainer.py:197 - evaluate() - Valid Loss: 3.16555(3.21031)
2023-01-22 22:53:06,323 - INFO - trainer.py:198 - evaluate() - Macro F1: 0.0415
2023-01-22 22:53:06,323 - INFO - trainer.py:199 - evaluate() - Time: 0:00:03
2023-01-22 22:53:06,323 - INFO - trainer.py:200 - evaluate() - **************************************************
2023-01-22 22:53:45,211 - INFO - trainer.py:123 - train_model() - **************************************************
2023-01-22 22:53:45,211 - INFO - trainer.py:124 - train_model() - TRAIN RECORD:
2023-01-22 22:53:45,212 - INFO - trainer.py:125 - train_model() - Fold: 3
2023-01-22 22:53:45,212 - INFO - trainer.py:126 - train_model() - Epoch: 002 [ 110/110 (100%)]
2023-01-22 22:53:45,231 - INFO - trainer.py:130 - train_model() - Train Loss: 2.30292(2.92256)
2023-01-22 22:53:45,231 - INFO - trainer.py:131 - train_model() - Grad: 276840.812
2023-01-22 22:53:45,232 - INFO - trainer.py:132 - train_model() - LR: 0.0000139944
2023-01-22 22:53:45,232 - INFO - trainer.py:133 - train_model() - Time: 0:02:09
2023-01-22 22:53:45,232 - INFO - trainer.py:134 - train_model() - **************************************************
2023-01-22 22:53:47,937 - INFO - trainer.py:190 - evaluate() - **************************************************
2023-01-22 22:53:47,938 - INFO - trainer.py:191 - evaluate() - Valid RECORD:
2023-01-22 22:53:47,938 - INFO - trainer.py:192 - evaluate() - Fold: 3
2023-01-22 22:53:47,938 - INFO - trainer.py:193 - evaluate() - Epoch: 002 [7/7 (100%)]
2023-01-22 22:53:47,938 - INFO - trainer.py:197 - evaluate() - Valid Loss: 2.79607(2.79761)
2023-01-22 22:53:47,938 - INFO - trainer.py:198 - evaluate() - Macro F1: 0.2149
2023-01-22 22:53:47,938 - INFO - trainer.py:199 - evaluate() - Time: 0:00:03
2023-01-22 22:53:47,938 - INFO - trainer.py:200 - evaluate() - **************************************************
2023-01-22 22:54:35,252 - INFO - trainer.py:123 - train_model() - **************************************************
2023-01-22 22:54:35,252 - INFO - trainer.py:124 - train_model() - TRAIN RECORD:
2023-01-22 22:54:35,252 - INFO - trainer.py:125 - train_model() - Fold: 3
2023-01-22 22:54:35,252 - INFO - trainer.py:126 - train_model() - Epoch: 003 [  61/110 ( 55%)]
2023-01-22 22:54:35,272 - INFO - trainer.py:130 - train_model() - Train Loss: 1.38570(2.68399)
2023-01-22 22:54:35,273 - INFO - trainer.py:131 - train_model() - Grad: 87909.867
2023-01-22 22:54:35,273 - INFO - trainer.py:132 - train_model() - LR: 0.0000139617
2023-01-22 22:54:35,273 - INFO - trainer.py:133 - train_model() - Time: 0:02:59
2023-01-22 22:54:35,273 - INFO - trainer.py:134 - train_model() - **************************************************
2023-01-22 22:54:37,981 - INFO - trainer.py:190 - evaluate() - **************************************************
2023-01-22 22:54:37,981 - INFO - trainer.py:191 - evaluate() - Valid RECORD:
2023-01-22 22:54:37,981 - INFO - trainer.py:192 - evaluate() - Fold: 3
2023-01-22 22:54:37,981 - INFO - trainer.py:193 - evaluate() - Epoch: 003 [7/7 (100%)]
2023-01-22 22:54:37,981 - INFO - trainer.py:197 - evaluate() - Valid Loss: 2.45380(2.49589)
2023-01-22 22:54:37,981 - INFO - trainer.py:198 - evaluate() - Macro F1: 0.3188
2023-01-22 22:54:37,981 - INFO - trainer.py:199 - evaluate() - Time: 0:00:03
2023-01-22 22:54:37,981 - INFO - trainer.py:200 - evaluate() - **************************************************
2023-01-22 22:55:17,062 - INFO - trainer.py:123 - train_model() - **************************************************
2023-01-22 22:55:17,063 - INFO - trainer.py:124 - train_model() - TRAIN RECORD:
2023-01-22 22:55:17,063 - INFO - trainer.py:125 - train_model() - Fold: 3
2023-01-22 22:55:17,063 - INFO - trainer.py:126 - train_model() - Epoch: 003 [ 110/110 (100%)]
2023-01-22 22:55:17,085 - INFO - trainer.py:130 - train_model() - Train Loss: 1.68034(2.51778)
2023-01-22 22:55:17,085 - INFO - trainer.py:131 - train_model() - Grad: 319435.125
2023-01-22 22:55:17,085 - INFO - trainer.py:132 - train_model() - LR: 0.0000138881
2023-01-22 22:55:17,085 - INFO - trainer.py:133 - train_model() - Time: 0:03:41
2023-01-22 22:55:17,085 - INFO - trainer.py:134 - train_model() - **************************************************
2023-01-22 22:55:19,789 - INFO - trainer.py:190 - evaluate() - **************************************************
2023-01-22 22:55:19,790 - INFO - trainer.py:191 - evaluate() - Valid RECORD:
2023-01-22 22:55:19,790 - INFO - trainer.py:192 - evaluate() - Fold: 3
2023-01-22 22:55:19,790 - INFO - trainer.py:193 - evaluate() - Epoch: 003 [7/7 (100%)]
2023-01-22 22:55:19,790 - INFO - trainer.py:197 - evaluate() - Valid Loss: 2.21167(2.32505)
2023-01-22 22:55:19,790 - INFO - trainer.py:198 - evaluate() - Macro F1: 0.3969
2023-01-22 22:55:19,790 - INFO - trainer.py:199 - evaluate() - Time: 0:00:03
2023-01-22 22:55:19,790 - INFO - trainer.py:200 - evaluate() - **************************************************
2023-01-22 22:56:07,227 - INFO - trainer.py:123 - train_model() - **************************************************
2023-01-22 22:56:07,227 - INFO - trainer.py:124 - train_model() - TRAIN RECORD:
2023-01-22 22:56:07,227 - INFO - trainer.py:125 - train_model() - Fold: 3
2023-01-22 22:56:07,227 - INFO - trainer.py:126 - train_model() - Epoch: 004 [  61/110 ( 55%)]
2023-01-22 22:56:07,250 - INFO - trainer.py:130 - train_model() - Train Loss: 1.00587(2.33557)
2023-01-22 22:56:07,250 - INFO - trainer.py:131 - train_model() - Grad: 69723.492
2023-01-22 22:56:07,250 - INFO - trainer.py:132 - train_model() - LR: 0.0000137385
2023-01-22 22:56:07,250 - INFO - trainer.py:133 - train_model() - Time: 0:04:31
2023-01-22 22:56:07,250 - INFO - trainer.py:134 - train_model() - **************************************************
2023-01-22 22:56:09,956 - INFO - trainer.py:190 - evaluate() - **************************************************
2023-01-22 22:56:09,957 - INFO - trainer.py:191 - evaluate() - Valid RECORD:
2023-01-22 22:56:09,957 - INFO - trainer.py:192 - evaluate() - Fold: 3
2023-01-22 22:56:09,957 - INFO - trainer.py:193 - evaluate() - Epoch: 004 [7/7 (100%)]
2023-01-22 22:56:09,957 - INFO - trainer.py:197 - evaluate() - Valid Loss: 2.04231(2.19662)
2023-01-22 22:56:09,957 - INFO - trainer.py:198 - evaluate() - Macro F1: 0.4624
2023-01-22 22:56:09,957 - INFO - trainer.py:199 - evaluate() - Time: 0:00:03
2023-01-22 22:56:09,957 - INFO - trainer.py:200 - evaluate() - **************************************************
2023-01-22 22:56:48,792 - INFO - trainer.py:123 - train_model() - **************************************************
2023-01-22 22:56:48,792 - INFO - trainer.py:124 - train_model() - TRAIN RECORD:
2023-01-22 22:56:48,792 - INFO - trainer.py:125 - train_model() - Fold: 3
2023-01-22 22:56:48,792 - INFO - trainer.py:126 - train_model() - Epoch: 004 [ 110/110 (100%)]
2023-01-22 22:56:48,812 - INFO - trainer.py:130 - train_model() - Train Loss: 1.59806(2.21368)
2023-01-22 22:56:48,812 - INFO - trainer.py:131 - train_model() - Grad: 273206.844
2023-01-22 22:56:48,812 - INFO - trainer.py:132 - train_model() - LR: 0.0000135725
2023-01-22 22:56:48,812 - INFO - trainer.py:133 - train_model() - Time: 0:05:13
2023-01-22 22:56:48,812 - INFO - trainer.py:134 - train_model() - **************************************************
2023-01-22 22:56:51,523 - INFO - trainer.py:190 - evaluate() - **************************************************
2023-01-22 22:56:51,523 - INFO - trainer.py:191 - evaluate() - Valid RECORD:
2023-01-22 22:56:51,523 - INFO - trainer.py:192 - evaluate() - Fold: 3
2023-01-22 22:56:51,523 - INFO - trainer.py:193 - evaluate() - Epoch: 004 [7/7 (100%)]
2023-01-22 22:56:51,523 - INFO - trainer.py:197 - evaluate() - Valid Loss: 2.06085(2.17047)
2023-01-22 22:56:51,524 - INFO - trainer.py:198 - evaluate() - Macro F1: 0.4720
2023-01-22 22:56:51,524 - INFO - trainer.py:199 - evaluate() - Time: 0:00:03
2023-01-22 22:56:51,524 - INFO - trainer.py:200 - evaluate() - **************************************************
2023-01-22 22:57:38,955 - INFO - trainer.py:123 - train_model() - **************************************************
2023-01-22 22:57:38,955 - INFO - trainer.py:124 - train_model() - TRAIN RECORD:
2023-01-22 22:57:38,955 - INFO - trainer.py:125 - train_model() - Fold: 3
2023-01-22 22:57:38,955 - INFO - trainer.py:126 - train_model() - Epoch: 005 [  61/110 ( 55%)]
2023-01-22 22:57:38,978 - INFO - trainer.py:130 - train_model() - Train Loss: 1.00201(2.08784)
2023-01-22 22:57:38,978 - INFO - trainer.py:131 - train_model() - Grad: 72960.523
2023-01-22 22:57:38,978 - INFO - trainer.py:132 - train_model() - LR: 0.0000133104
2023-01-22 22:57:38,978 - INFO - trainer.py:133 - train_model() - Time: 0:06:03
2023-01-22 22:57:38,978 - INFO - trainer.py:134 - train_model() - **************************************************
2023-01-22 22:57:41,688 - INFO - trainer.py:190 - evaluate() - **************************************************
2023-01-22 22:57:41,689 - INFO - trainer.py:191 - evaluate() - Valid RECORD:
2023-01-22 22:57:41,689 - INFO - trainer.py:192 - evaluate() - Fold: 3
2023-01-22 22:57:41,689 - INFO - trainer.py:193 - evaluate() - Epoch: 005 [7/7 (100%)]
2023-01-22 22:57:41,689 - INFO - trainer.py:197 - evaluate() - Valid Loss: 1.99683(2.13125)
2023-01-22 22:57:41,689 - INFO - trainer.py:198 - evaluate() - Macro F1: 0.4681
2023-01-22 22:57:41,689 - INFO - trainer.py:199 - evaluate() - Time: 0:00:03
2023-01-22 22:57:41,689 - INFO - trainer.py:200 - evaluate() - **************************************************
2023-01-22 22:57:41,689 - INFO - function_utils.py:301 - __call__() - EarlyStopping counter: 1 out of 6
2023-01-22 22:58:15,405 - INFO - trainer.py:123 - train_model() - **************************************************
2023-01-22 22:58:15,405 - INFO - trainer.py:124 - train_model() - TRAIN RECORD:
2023-01-22 22:58:15,405 - INFO - trainer.py:125 - train_model() - Fold: 3
2023-01-22 22:58:15,405 - INFO - trainer.py:126 - train_model() - Epoch: 005 [ 110/110 (100%)]
2023-01-22 22:58:15,426 - INFO - trainer.py:130 - train_model() - Train Loss: 0.58143(2.00247)
2023-01-22 22:58:15,426 - INFO - trainer.py:131 - train_model() - Grad: 148537.422
2023-01-22 22:58:15,426 - INFO - trainer.py:132 - train_model() - LR: 0.0000130570
2023-01-22 22:58:15,426 - INFO - trainer.py:133 - train_model() - Time: 0:06:40
2023-01-22 22:58:15,426 - INFO - trainer.py:134 - train_model() - **************************************************
2023-01-22 22:58:18,138 - INFO - trainer.py:190 - evaluate() - **************************************************
2023-01-22 22:58:18,138 - INFO - trainer.py:191 - evaluate() - Valid RECORD:
2023-01-22 22:58:18,138 - INFO - trainer.py:192 - evaluate() - Fold: 3
2023-01-22 22:58:18,138 - INFO - trainer.py:193 - evaluate() - Epoch: 005 [7/7 (100%)]
2023-01-22 22:58:18,138 - INFO - trainer.py:197 - evaluate() - Valid Loss: 1.92838(2.10244)
2023-01-22 22:58:18,139 - INFO - trainer.py:198 - evaluate() - Macro F1: 0.4776
2023-01-22 22:58:18,139 - INFO - trainer.py:199 - evaluate() - Time: 0:00:03
2023-01-22 22:58:18,139 - INFO - trainer.py:200 - evaluate() - **************************************************
2023-01-22 22:59:05,541 - INFO - trainer.py:123 - train_model() - **************************************************
2023-01-22 22:59:05,541 - INFO - trainer.py:124 - train_model() - TRAIN RECORD:
2023-01-22 22:59:05,541 - INFO - trainer.py:125 - train_model() - Fold: 3
2023-01-22 22:59:05,541 - INFO - trainer.py:126 - train_model() - Epoch: 006 [  61/110 ( 55%)]
2023-01-22 22:59:05,565 - INFO - trainer.py:130 - train_model() - Train Loss: 0.68774(1.90254)
2023-01-22 22:59:05,565 - INFO - trainer.py:131 - train_model() - Grad: 49985.742
2023-01-22 22:59:05,566 - INFO - trainer.py:132 - train_model() - LR: 0.0000126905
2023-01-22 22:59:05,566 - INFO - trainer.py:133 - train_model() - Time: 0:07:30
2023-01-22 22:59:05,566 - INFO - trainer.py:134 - train_model() - **************************************************
2023-01-22 22:59:08,276 - INFO - trainer.py:190 - evaluate() - **************************************************
2023-01-22 22:59:08,276 - INFO - trainer.py:191 - evaluate() - Valid RECORD:
2023-01-22 22:59:08,276 - INFO - trainer.py:192 - evaluate() - Fold: 3
2023-01-22 22:59:08,276 - INFO - trainer.py:193 - evaluate() - Epoch: 006 [7/7 (100%)]
2023-01-22 22:59:08,276 - INFO - trainer.py:197 - evaluate() - Valid Loss: 1.91150(2.06441)
2023-01-22 22:59:08,276 - INFO - trainer.py:198 - evaluate() - Macro F1: 0.5211
2023-01-22 22:59:08,277 - INFO - trainer.py:199 - evaluate() - Time: 0:00:03
2023-01-22 22:59:08,277 - INFO - trainer.py:200 - evaluate() - **************************************************
2023-01-22 22:59:47,264 - INFO - trainer.py:123 - train_model() - **************************************************
2023-01-22 22:59:47,264 - INFO - trainer.py:124 - train_model() - TRAIN RECORD:
2023-01-22 22:59:47,264 - INFO - trainer.py:125 - train_model() - Fold: 3
2023-01-22 22:59:47,264 - INFO - trainer.py:126 - train_model() - Epoch: 006 [ 110/110 (100%)]
2023-01-22 22:59:47,288 - INFO - trainer.py:130 - train_model() - Train Loss: 0.12440(1.83269)
2023-01-22 22:59:47,288 - INFO - trainer.py:131 - train_model() - Grad: 11482.794
2023-01-22 22:59:47,288 - INFO - trainer.py:132 - train_model() - LR: 0.0000123574
2023-01-22 22:59:47,288 - INFO - trainer.py:133 - train_model() - Time: 0:08:11
2023-01-22 22:59:47,288 - INFO - trainer.py:134 - train_model() - **************************************************
2023-01-22 22:59:49,992 - INFO - trainer.py:190 - evaluate() - **************************************************
2023-01-22 22:59:49,992 - INFO - trainer.py:191 - evaluate() - Valid RECORD:
2023-01-22 22:59:49,992 - INFO - trainer.py:192 - evaluate() - Fold: 3
2023-01-22 22:59:49,992 - INFO - trainer.py:193 - evaluate() - Epoch: 006 [7/7 (100%)]
2023-01-22 22:59:49,993 - INFO - trainer.py:197 - evaluate() - Valid Loss: 1.81403(2.04739)
2023-01-22 22:59:49,993 - INFO - trainer.py:198 - evaluate() - Macro F1: 0.5037
2023-01-22 22:59:49,993 - INFO - trainer.py:199 - evaluate() - Time: 0:00:03
2023-01-22 22:59:49,993 - INFO - trainer.py:200 - evaluate() - **************************************************
2023-01-22 22:59:49,993 - INFO - function_utils.py:301 - __call__() - EarlyStopping counter: 1 out of 6
2023-01-22 23:00:32,258 - INFO - trainer.py:123 - train_model() - **************************************************
2023-01-22 23:00:32,259 - INFO - trainer.py:124 - train_model() - TRAIN RECORD:
2023-01-22 23:00:32,259 - INFO - trainer.py:125 - train_model() - Fold: 3
2023-01-22 23:00:32,259 - INFO - trainer.py:126 - train_model() - Epoch: 007 [  61/110 ( 55%)]
2023-01-22 23:00:32,282 - INFO - trainer.py:130 - train_model() - Train Loss: 1.01158(1.75468)
2023-01-22 23:00:32,283 - INFO - trainer.py:131 - train_model() - Grad: 94341.234
2023-01-22 23:00:32,283 - INFO - trainer.py:132 - train_model() - LR: 0.0000118977
2023-01-22 23:00:32,283 - INFO - trainer.py:133 - train_model() - Time: 0:08:56
2023-01-22 23:00:32,283 - INFO - trainer.py:134 - train_model() - **************************************************
2023-01-22 23:00:34,997 - INFO - trainer.py:190 - evaluate() - **************************************************
2023-01-22 23:00:34,997 - INFO - trainer.py:191 - evaluate() - Valid RECORD:
2023-01-22 23:00:34,997 - INFO - trainer.py:192 - evaluate() - Fold: 3
2023-01-22 23:00:34,997 - INFO - trainer.py:193 - evaluate() - Epoch: 007 [7/7 (100%)]
2023-01-22 23:00:34,997 - INFO - trainer.py:197 - evaluate() - Valid Loss: 1.90662(2.08297)
2023-01-22 23:00:34,997 - INFO - trainer.py:198 - evaluate() - Macro F1: 0.4978
2023-01-22 23:00:34,997 - INFO - trainer.py:199 - evaluate() - Time: 0:00:03
2023-01-22 23:00:34,997 - INFO - trainer.py:200 - evaluate() - **************************************************
2023-01-22 23:00:34,997 - INFO - function_utils.py:301 - __call__() - EarlyStopping counter: 2 out of 6
2023-01-22 23:01:08,723 - INFO - trainer.py:123 - train_model() - **************************************************
2023-01-22 23:01:08,723 - INFO - trainer.py:124 - train_model() - TRAIN RECORD:
2023-01-22 23:01:08,723 - INFO - trainer.py:125 - train_model() - Fold: 3
2023-01-22 23:01:08,723 - INFO - trainer.py:126 - train_model() - Epoch: 007 [ 110/110 (100%)]
2023-01-22 23:01:08,743 - INFO - trainer.py:130 - train_model() - Train Loss: 0.54078(1.69766)
2023-01-22 23:01:08,743 - INFO - trainer.py:131 - train_model() - Grad: 139942.969
2023-01-22 23:01:08,743 - INFO - trainer.py:132 - train_model() - LR: 0.0000114949
2023-01-22 23:01:08,743 - INFO - trainer.py:133 - train_model() - Time: 0:09:33
2023-01-22 23:01:08,743 - INFO - trainer.py:134 - train_model() - **************************************************
2023-01-22 23:01:11,453 - INFO - trainer.py:190 - evaluate() - **************************************************
2023-01-22 23:01:11,454 - INFO - trainer.py:191 - evaluate() - Valid RECORD:
2023-01-22 23:01:11,454 - INFO - trainer.py:192 - evaluate() - Fold: 3
2023-01-22 23:01:11,454 - INFO - trainer.py:193 - evaluate() - Epoch: 007 [7/7 (100%)]
2023-01-22 23:01:11,454 - INFO - trainer.py:197 - evaluate() - Valid Loss: 1.90938(2.07505)
2023-01-22 23:01:11,454 - INFO - trainer.py:198 - evaluate() - Macro F1: 0.5169
2023-01-22 23:01:11,454 - INFO - trainer.py:199 - evaluate() - Time: 0:00:03
2023-01-22 23:01:11,454 - INFO - trainer.py:200 - evaluate() - **************************************************
2023-01-22 23:01:11,454 - INFO - function_utils.py:301 - __call__() - EarlyStopping counter: 3 out of 6
2023-01-22 23:01:53,763 - INFO - trainer.py:123 - train_model() - **************************************************
2023-01-22 23:01:53,764 - INFO - trainer.py:124 - train_model() - TRAIN RECORD:
2023-01-22 23:01:53,764 - INFO - trainer.py:125 - train_model() - Fold: 3
2023-01-22 23:01:53,764 - INFO - trainer.py:126 - train_model() - Epoch: 008 [  61/110 ( 55%)]
2023-01-22 23:01:53,784 - INFO - trainer.py:130 - train_model() - Train Loss: 0.86632(1.63312)
2023-01-22 23:01:53,784 - INFO - trainer.py:131 - train_model() - Grad: 83631.297
2023-01-22 23:01:53,784 - INFO - trainer.py:132 - train_model() - LR: 0.0000109559
2023-01-22 23:01:53,784 - INFO - trainer.py:133 - train_model() - Time: 0:10:18
2023-01-22 23:01:53,784 - INFO - trainer.py:134 - train_model() - **************************************************
2023-01-22 23:01:56,500 - INFO - trainer.py:190 - evaluate() - **************************************************
2023-01-22 23:01:56,500 - INFO - trainer.py:191 - evaluate() - Valid RECORD:
2023-01-22 23:01:56,500 - INFO - trainer.py:192 - evaluate() - Fold: 3
2023-01-22 23:01:56,500 - INFO - trainer.py:193 - evaluate() - Epoch: 008 [7/7 (100%)]
2023-01-22 23:01:56,500 - INFO - trainer.py:197 - evaluate() - Valid Loss: 1.86493(2.06306)
2023-01-22 23:01:56,500 - INFO - trainer.py:198 - evaluate() - Macro F1: 0.5034
2023-01-22 23:01:56,500 - INFO - trainer.py:199 - evaluate() - Time: 0:00:03
2023-01-22 23:01:56,500 - INFO - trainer.py:200 - evaluate() - **************************************************
2023-01-22 23:01:56,500 - INFO - function_utils.py:301 - __call__() - EarlyStopping counter: 4 out of 6
2023-01-22 23:02:30,286 - INFO - trainer.py:123 - train_model() - **************************************************
2023-01-22 23:02:30,286 - INFO - trainer.py:124 - train_model() - TRAIN RECORD:
2023-01-22 23:02:30,286 - INFO - trainer.py:125 - train_model() - Fold: 3
2023-01-22 23:02:30,287 - INFO - trainer.py:126 - train_model() - Epoch: 008 [ 110/110 (100%)]
2023-01-22 23:02:30,309 - INFO - trainer.py:130 - train_model() - Train Loss: 0.64913(1.58949)
2023-01-22 23:02:30,309 - INFO - trainer.py:131 - train_model() - Grad: 108923.875
2023-01-22 23:02:30,309 - INFO - trainer.py:132 - train_model() - LR: 0.0000104958
2023-01-22 23:02:30,309 - INFO - trainer.py:133 - train_model() - Time: 0:10:54
2023-01-22 23:02:30,309 - INFO - trainer.py:134 - train_model() - **************************************************
2023-01-22 23:02:33,023 - INFO - trainer.py:190 - evaluate() - **************************************************
2023-01-22 23:02:33,023 - INFO - trainer.py:191 - evaluate() - Valid RECORD:
2023-01-22 23:02:33,023 - INFO - trainer.py:192 - evaluate() - Fold: 3
2023-01-22 23:02:33,024 - INFO - trainer.py:193 - evaluate() - Epoch: 008 [7/7 (100%)]
2023-01-22 23:02:33,024 - INFO - trainer.py:197 - evaluate() - Valid Loss: 1.89666(2.04820)
2023-01-22 23:02:33,024 - INFO - trainer.py:198 - evaluate() - Macro F1: 0.5057
2023-01-22 23:02:33,024 - INFO - trainer.py:199 - evaluate() - Time: 0:00:03
2023-01-22 23:02:33,024 - INFO - trainer.py:200 - evaluate() - **************************************************
2023-01-22 23:02:33,024 - INFO - function_utils.py:301 - __call__() - EarlyStopping counter: 5 out of 6
2023-01-22 23:03:15,331 - INFO - trainer.py:123 - train_model() - **************************************************
2023-01-22 23:03:15,331 - INFO - trainer.py:124 - train_model() - TRAIN RECORD:
2023-01-22 23:03:15,331 - INFO - trainer.py:125 - train_model() - Fold: 3
2023-01-22 23:03:15,331 - INFO - trainer.py:126 - train_model() - Epoch: 009 [  61/110 ( 55%)]
2023-01-22 23:03:15,355 - INFO - trainer.py:130 - train_model() - Train Loss: 0.58066(1.53766)
2023-01-22 23:03:15,356 - INFO - trainer.py:131 - train_model() - Grad: 57612.371
2023-01-22 23:03:15,356 - INFO - trainer.py:132 - train_model() - LR: 0.0000098939
2023-01-22 23:03:15,356 - INFO - trainer.py:133 - train_model() - Time: 0:11:40
2023-01-22 23:03:15,356 - INFO - trainer.py:134 - train_model() - **************************************************
2023-01-22 23:03:18,064 - INFO - trainer.py:190 - evaluate() - **************************************************
2023-01-22 23:03:18,064 - INFO - trainer.py:191 - evaluate() - Valid RECORD:
2023-01-22 23:03:18,064 - INFO - trainer.py:192 - evaluate() - Fold: 3
2023-01-22 23:03:18,064 - INFO - trainer.py:193 - evaluate() - Epoch: 009 [7/7 (100%)]
2023-01-22 23:03:18,064 - INFO - trainer.py:197 - evaluate() - Valid Loss: 1.92148(2.08352)
2023-01-22 23:03:18,064 - INFO - trainer.py:198 - evaluate() - Macro F1: 0.5054
2023-01-22 23:03:18,064 - INFO - trainer.py:199 - evaluate() - Time: 0:00:03
2023-01-22 23:03:18,064 - INFO - trainer.py:200 - evaluate() - **************************************************
2023-01-22 23:03:18,064 - INFO - function_utils.py:301 - __call__() - EarlyStopping counter: 6 out of 6
2023-01-22 23:03:18,065 - INFO - trainer.py:144 - train_model() - ========== fold: 3 result ==========
2023-01-22 23:03:18,065 - INFO - trainer.py:145 - train_model() - {'[fold3] valid best score taskC': 0.5210923725717731}
2023-01-22 23:03:18,065 - INFO - trainer.py:148 - train_model() - {'[fold3] valid best score taskC': 0.5210923725717731}
2023-01-22 23:03:21,666 - INFO - trainer.py:53 - train_model() - ***** Running training *****
2023-01-22 23:03:21,666 - INFO - trainer.py:54 - train_model() -   Num Train examples = 110
2023-01-22 23:03:21,666 - INFO - trainer.py:55 - train_model() -   Num Valid examples = 7
2023-01-22 23:03:21,666 - INFO - trainer.py:56 - train_model() -   Num Epochs = 20
2023-01-22 23:03:21,666 - INFO - trainer.py:57 - train_model() -   Train batch size = 30
2023-01-22 23:03:21,666 - INFO - trainer.py:58 - train_model() -   Batch interval = 60
2023-01-22 23:03:21,666 - INFO - trainer.py:59 - train_model() -   Logging steps = 50
2023-01-22 23:03:21,666 - INFO - trainer.py:60 - train_model() -   Gradient Accumulation steps = 1
2023-01-22 23:03:41,220 - INFO - trainer.py:123 - train_model() - **************************************************
2023-01-22 23:03:41,220 - INFO - trainer.py:124 - train_model() - TRAIN RECORD:
2023-01-22 23:03:41,220 - INFO - trainer.py:125 - train_model() - Fold: 4
2023-01-22 23:03:41,220 - INFO - trainer.py:126 - train_model() - Epoch: 001 [  61/110 ( 55%)]
2023-01-22 23:03:41,241 - INFO - trainer.py:130 - train_model() - Train Loss: 3.07626(3.07571)
2023-01-22 23:03:41,241 - INFO - trainer.py:131 - train_model() - Grad: 51836.988
2023-01-22 23:03:41,241 - INFO - trainer.py:132 - train_model() - LR: 0.0000038803
2023-01-22 23:03:41,242 - INFO - trainer.py:133 - train_model() - Time: 0:00:20
2023-01-22 23:03:41,242 - INFO - trainer.py:134 - train_model() - **************************************************
2023-01-22 23:03:43,965 - INFO - trainer.py:190 - evaluate() - **************************************************
2023-01-22 23:03:43,965 - INFO - trainer.py:191 - evaluate() - Valid RECORD:
2023-01-22 23:03:43,965 - INFO - trainer.py:192 - evaluate() - Fold: 4
2023-01-22 23:03:43,965 - INFO - trainer.py:193 - evaluate() - Epoch: 001 [7/7 (100%)]
2023-01-22 23:03:43,965 - INFO - trainer.py:197 - evaluate() - Valid Loss: 3.28382(3.32100)
2023-01-22 23:03:43,965 - INFO - trainer.py:198 - evaluate() - Macro F1: 0.0144
2023-01-22 23:03:43,966 - INFO - trainer.py:199 - evaluate() - Time: 0:00:03
2023-01-22 23:03:43,966 - INFO - trainer.py:200 - evaluate() - **************************************************
2023-01-22 23:04:04,361 - INFO - trainer.py:123 - train_model() - **************************************************
2023-01-22 23:04:04,361 - INFO - trainer.py:124 - train_model() - TRAIN RECORD:
2023-01-22 23:04:04,361 - INFO - trainer.py:125 - train_model() - Fold: 4
2023-01-22 23:04:04,361 - INFO - trainer.py:126 - train_model() - Epoch: 001 [ 110/110 (100%)]
2023-01-22 23:04:04,361 - INFO - trainer.py:130 - train_model() - Train Loss: 2.35270(3.06359)
2023-01-22 23:04:04,361 - INFO - trainer.py:131 - train_model() - Grad: inf
2023-01-22 23:04:04,361 - INFO - trainer.py:132 - train_model() - LR: 0.0000069972
2023-01-22 23:04:04,361 - INFO - trainer.py:133 - train_model() - Time: 0:00:43
2023-01-22 23:04:04,361 - INFO - trainer.py:134 - train_model() - **************************************************
2023-01-22 23:04:07,061 - INFO - trainer.py:190 - evaluate() - **************************************************
2023-01-22 23:04:07,062 - INFO - trainer.py:191 - evaluate() - Valid RECORD:
2023-01-22 23:04:07,062 - INFO - trainer.py:192 - evaluate() - Fold: 4
2023-01-22 23:04:07,062 - INFO - trainer.py:193 - evaluate() - Epoch: 001 [7/7 (100%)]
2023-01-22 23:04:07,062 - INFO - trainer.py:197 - evaluate() - Valid Loss: 3.25280(3.30649)
2023-01-22 23:04:07,062 - INFO - trainer.py:198 - evaluate() - Macro F1: 0.0156
2023-01-22 23:04:07,062 - INFO - trainer.py:199 - evaluate() - Time: 0:00:03
2023-01-22 23:04:07,062 - INFO - trainer.py:200 - evaluate() - **************************************************
2023-01-22 23:04:54,384 - INFO - trainer.py:123 - train_model() - **************************************************
2023-01-22 23:04:54,384 - INFO - trainer.py:124 - train_model() - TRAIN RECORD:
2023-01-22 23:04:54,385 - INFO - trainer.py:125 - train_model() - Fold: 4
2023-01-22 23:04:54,385 - INFO - trainer.py:126 - train_model() - Epoch: 002 [  61/110 ( 55%)]
2023-01-22 23:04:54,404 - INFO - trainer.py:130 - train_model() - Train Loss: 2.74860(3.02740)
2023-01-22 23:04:54,405 - INFO - trainer.py:131 - train_model() - Grad: 33249.695
2023-01-22 23:04:54,405 - INFO - trainer.py:132 - train_model() - LR: 0.0000108775
2023-01-22 23:04:54,405 - INFO - trainer.py:133 - train_model() - Time: 0:01:33
2023-01-22 23:04:54,405 - INFO - trainer.py:134 - train_model() - **************************************************
2023-01-22 23:04:57,111 - INFO - trainer.py:190 - evaluate() - **************************************************
2023-01-22 23:04:57,111 - INFO - trainer.py:191 - evaluate() - Valid RECORD:
2023-01-22 23:04:57,111 - INFO - trainer.py:192 - evaluate() - Fold: 4
2023-01-22 23:04:57,111 - INFO - trainer.py:193 - evaluate() - Epoch: 002 [7/7 (100%)]
2023-01-22 23:04:57,111 - INFO - trainer.py:197 - evaluate() - Valid Loss: 3.12986(3.20226)
2023-01-22 23:04:57,111 - INFO - trainer.py:198 - evaluate() - Macro F1: 0.0375
2023-01-22 23:04:57,111 - INFO - trainer.py:199 - evaluate() - Time: 0:00:03
2023-01-22 23:04:57,112 - INFO - trainer.py:200 - evaluate() - **************************************************
2023-01-22 23:05:36,030 - INFO - trainer.py:123 - train_model() - **************************************************
2023-01-22 23:05:36,031 - INFO - trainer.py:124 - train_model() - TRAIN RECORD:
2023-01-22 23:05:36,031 - INFO - trainer.py:125 - train_model() - Fold: 4
2023-01-22 23:05:36,031 - INFO - trainer.py:126 - train_model() - Epoch: 002 [ 110/110 (100%)]
2023-01-22 23:05:36,052 - INFO - trainer.py:130 - train_model() - Train Loss: 2.55729(2.90165)
2023-01-22 23:05:36,053 - INFO - trainer.py:131 - train_model() - Grad: 156076.812
2023-01-22 23:05:36,053 - INFO - trainer.py:132 - train_model() - LR: 0.0000139944
2023-01-22 23:05:36,053 - INFO - trainer.py:133 - train_model() - Time: 0:02:14
2023-01-22 23:05:36,053 - INFO - trainer.py:134 - train_model() - **************************************************
2023-01-22 23:05:38,755 - INFO - trainer.py:190 - evaluate() - **************************************************
2023-01-22 23:05:38,755 - INFO - trainer.py:191 - evaluate() - Valid RECORD:
2023-01-22 23:05:38,755 - INFO - trainer.py:192 - evaluate() - Fold: 4
2023-01-22 23:05:38,755 - INFO - trainer.py:193 - evaluate() - Epoch: 002 [7/7 (100%)]
2023-01-22 23:05:38,755 - INFO - trainer.py:197 - evaluate() - Valid Loss: 2.39183(2.62885)
2023-01-22 23:05:38,755 - INFO - trainer.py:198 - evaluate() - Macro F1: 0.2480
2023-01-22 23:05:38,755 - INFO - trainer.py:199 - evaluate() - Time: 0:00:03
2023-01-22 23:05:38,755 - INFO - trainer.py:200 - evaluate() - **************************************************
2023-01-22 23:06:26,052 - INFO - trainer.py:123 - train_model() - **************************************************
2023-01-22 23:06:26,052 - INFO - trainer.py:124 - train_model() - TRAIN RECORD:
2023-01-22 23:06:26,053 - INFO - trainer.py:125 - train_model() - Fold: 4
2023-01-22 23:06:26,053 - INFO - trainer.py:126 - train_model() - Epoch: 003 [  61/110 ( 55%)]
2023-01-22 23:06:26,075 - INFO - trainer.py:130 - train_model() - Train Loss: 1.55568(2.68168)
2023-01-22 23:06:26,075 - INFO - trainer.py:131 - train_model() - Grad: 45639.949
2023-01-22 23:06:26,075 - INFO - trainer.py:132 - train_model() - LR: 0.0000139617
2023-01-22 23:06:26,075 - INFO - trainer.py:133 - train_model() - Time: 0:03:04
2023-01-22 23:06:26,075 - INFO - trainer.py:134 - train_model() - **************************************************
2023-01-22 23:06:28,786 - INFO - trainer.py:190 - evaluate() - **************************************************
2023-01-22 23:06:28,786 - INFO - trainer.py:191 - evaluate() - Valid RECORD:
2023-01-22 23:06:28,786 - INFO - trainer.py:192 - evaluate() - Fold: 4
2023-01-22 23:06:28,786 - INFO - trainer.py:193 - evaluate() - Epoch: 003 [7/7 (100%)]
2023-01-22 23:06:28,787 - INFO - trainer.py:197 - evaluate() - Valid Loss: 2.15908(2.38576)
2023-01-22 23:06:28,787 - INFO - trainer.py:198 - evaluate() - Macro F1: 0.3548
2023-01-22 23:06:28,787 - INFO - trainer.py:199 - evaluate() - Time: 0:00:03
2023-01-22 23:06:28,787 - INFO - trainer.py:200 - evaluate() - **************************************************
2023-01-22 23:07:07,589 - INFO - trainer.py:123 - train_model() - **************************************************
2023-01-22 23:07:07,589 - INFO - trainer.py:124 - train_model() - TRAIN RECORD:
2023-01-22 23:07:07,589 - INFO - trainer.py:125 - train_model() - Fold: 4
2023-01-22 23:07:07,589 - INFO - trainer.py:126 - train_model() - Epoch: 003 [ 110/110 (100%)]
2023-01-22 23:07:07,611 - INFO - trainer.py:130 - train_model() - Train Loss: 1.79575(2.51733)
2023-01-22 23:07:07,612 - INFO - trainer.py:131 - train_model() - Grad: 175802.094
2023-01-22 23:07:07,612 - INFO - trainer.py:132 - train_model() - LR: 0.0000138881
2023-01-22 23:07:07,612 - INFO - trainer.py:133 - train_model() - Time: 0:03:46
2023-01-22 23:07:07,612 - INFO - trainer.py:134 - train_model() - **************************************************
2023-01-22 23:07:10,321 - INFO - trainer.py:190 - evaluate() - **************************************************
2023-01-22 23:07:10,321 - INFO - trainer.py:191 - evaluate() - Valid RECORD:
2023-01-22 23:07:10,321 - INFO - trainer.py:192 - evaluate() - Fold: 4
2023-01-22 23:07:10,321 - INFO - trainer.py:193 - evaluate() - Epoch: 003 [7/7 (100%)]
2023-01-22 23:07:10,321 - INFO - trainer.py:197 - evaluate() - Valid Loss: 2.04692(2.26058)
2023-01-22 23:07:10,321 - INFO - trainer.py:198 - evaluate() - Macro F1: 0.4065
2023-01-22 23:07:10,321 - INFO - trainer.py:199 - evaluate() - Time: 0:00:03
2023-01-22 23:07:10,321 - INFO - trainer.py:200 - evaluate() - **************************************************
2023-01-22 23:07:57,544 - INFO - trainer.py:123 - train_model() - **************************************************
2023-01-22 23:07:57,544 - INFO - trainer.py:124 - train_model() - TRAIN RECORD:
2023-01-22 23:07:57,544 - INFO - trainer.py:125 - train_model() - Fold: 4
2023-01-22 23:07:57,545 - INFO - trainer.py:126 - train_model() - Epoch: 004 [  61/110 ( 55%)]
2023-01-22 23:07:57,565 - INFO - trainer.py:130 - train_model() - Train Loss: 1.23318(2.33868)
2023-01-22 23:07:57,565 - INFO - trainer.py:131 - train_model() - Grad: 38944.449
2023-01-22 23:07:57,565 - INFO - trainer.py:132 - train_model() - LR: 0.0000137385
2023-01-22 23:07:57,565 - INFO - trainer.py:133 - train_model() - Time: 0:04:36
2023-01-22 23:07:57,565 - INFO - trainer.py:134 - train_model() - **************************************************
2023-01-22 23:08:00,274 - INFO - trainer.py:190 - evaluate() - **************************************************
2023-01-22 23:08:00,274 - INFO - trainer.py:191 - evaluate() - Valid RECORD:
2023-01-22 23:08:00,274 - INFO - trainer.py:192 - evaluate() - Fold: 4
2023-01-22 23:08:00,274 - INFO - trainer.py:193 - evaluate() - Epoch: 004 [7/7 (100%)]
2023-01-22 23:08:00,275 - INFO - trainer.py:197 - evaluate() - Valid Loss: 1.92032(2.18347)
2023-01-22 23:08:00,275 - INFO - trainer.py:198 - evaluate() - Macro F1: 0.4212
2023-01-22 23:08:00,275 - INFO - trainer.py:199 - evaluate() - Time: 0:00:03
2023-01-22 23:08:00,275 - INFO - trainer.py:200 - evaluate() - **************************************************
2023-01-22 23:08:38,971 - INFO - trainer.py:123 - train_model() - **************************************************
2023-01-22 23:08:38,971 - INFO - trainer.py:124 - train_model() - TRAIN RECORD:
2023-01-22 23:08:38,971 - INFO - trainer.py:125 - train_model() - Fold: 4
2023-01-22 23:08:38,971 - INFO - trainer.py:126 - train_model() - Epoch: 004 [ 110/110 (100%)]
2023-01-22 23:08:38,992 - INFO - trainer.py:130 - train_model() - Train Loss: 1.03093(2.21275)
2023-01-22 23:08:38,992 - INFO - trainer.py:131 - train_model() - Grad: 94364.742
2023-01-22 23:08:38,992 - INFO - trainer.py:132 - train_model() - LR: 0.0000135725
2023-01-22 23:08:38,992 - INFO - trainer.py:133 - train_model() - Time: 0:05:17
2023-01-22 23:08:38,992 - INFO - trainer.py:134 - train_model() - **************************************************
2023-01-22 23:08:41,702 - INFO - trainer.py:190 - evaluate() - **************************************************
2023-01-22 23:08:41,702 - INFO - trainer.py:191 - evaluate() - Valid RECORD:
2023-01-22 23:08:41,702 - INFO - trainer.py:192 - evaluate() - Fold: 4
2023-01-22 23:08:41,702 - INFO - trainer.py:193 - evaluate() - Epoch: 004 [7/7 (100%)]
2023-01-22 23:08:41,702 - INFO - trainer.py:197 - evaluate() - Valid Loss: 1.94198(2.15349)
2023-01-22 23:08:41,702 - INFO - trainer.py:198 - evaluate() - Macro F1: 0.4498
2023-01-22 23:08:41,702 - INFO - trainer.py:199 - evaluate() - Time: 0:00:03
2023-01-22 23:08:41,702 - INFO - trainer.py:200 - evaluate() - **************************************************
2023-01-22 23:09:28,924 - INFO - trainer.py:123 - train_model() - **************************************************
2023-01-22 23:09:28,924 - INFO - trainer.py:124 - train_model() - TRAIN RECORD:
2023-01-22 23:09:28,924 - INFO - trainer.py:125 - train_model() - Fold: 4
2023-01-22 23:09:28,924 - INFO - trainer.py:126 - train_model() - Epoch: 005 [  61/110 ( 55%)]
2023-01-22 23:09:28,945 - INFO - trainer.py:130 - train_model() - Train Loss: 1.06618(2.07685)
2023-01-22 23:09:28,945 - INFO - trainer.py:131 - train_model() - Grad: 42015.949
2023-01-22 23:09:28,945 - INFO - trainer.py:132 - train_model() - LR: 0.0000133104
2023-01-22 23:09:28,945 - INFO - trainer.py:133 - train_model() - Time: 0:06:07
2023-01-22 23:09:28,945 - INFO - trainer.py:134 - train_model() - **************************************************
2023-01-22 23:09:31,654 - INFO - trainer.py:190 - evaluate() - **************************************************
2023-01-22 23:09:31,654 - INFO - trainer.py:191 - evaluate() - Valid RECORD:
2023-01-22 23:09:31,654 - INFO - trainer.py:192 - evaluate() - Fold: 4
2023-01-22 23:09:31,654 - INFO - trainer.py:193 - evaluate() - Epoch: 005 [7/7 (100%)]
2023-01-22 23:09:31,655 - INFO - trainer.py:197 - evaluate() - Valid Loss: 1.93682(2.11621)
2023-01-22 23:09:31,655 - INFO - trainer.py:198 - evaluate() - Macro F1: 0.4814
2023-01-22 23:09:31,655 - INFO - trainer.py:199 - evaluate() - Time: 0:00:03
2023-01-22 23:09:31,655 - INFO - trainer.py:200 - evaluate() - **************************************************
2023-01-22 23:10:10,365 - INFO - trainer.py:123 - train_model() - **************************************************
2023-01-22 23:10:10,365 - INFO - trainer.py:124 - train_model() - TRAIN RECORD:
2023-01-22 23:10:10,365 - INFO - trainer.py:125 - train_model() - Fold: 4
2023-01-22 23:10:10,365 - INFO - trainer.py:126 - train_model() - Epoch: 005 [ 110/110 (100%)]
2023-01-22 23:10:10,390 - INFO - trainer.py:130 - train_model() - Train Loss: 0.06166(1.98705)
2023-01-22 23:10:10,390 - INFO - trainer.py:131 - train_model() - Grad: 6819.717
2023-01-22 23:10:10,390 - INFO - trainer.py:132 - train_model() - LR: 0.0000130570
2023-01-22 23:10:10,390 - INFO - trainer.py:133 - train_model() - Time: 0:06:49
2023-01-22 23:10:10,391 - INFO - trainer.py:134 - train_model() - **************************************************
2023-01-22 23:10:13,095 - INFO - trainer.py:190 - evaluate() - **************************************************
2023-01-22 23:10:13,095 - INFO - trainer.py:191 - evaluate() - Valid RECORD:
2023-01-22 23:10:13,095 - INFO - trainer.py:192 - evaluate() - Fold: 4
2023-01-22 23:10:13,095 - INFO - trainer.py:193 - evaluate() - Epoch: 005 [7/7 (100%)]
2023-01-22 23:10:13,095 - INFO - trainer.py:197 - evaluate() - Valid Loss: 1.91135(2.09796)
2023-01-22 23:10:13,095 - INFO - trainer.py:198 - evaluate() - Macro F1: 0.4947
2023-01-22 23:10:13,095 - INFO - trainer.py:199 - evaluate() - Time: 0:00:03
2023-01-22 23:10:13,095 - INFO - trainer.py:200 - evaluate() - **************************************************
2023-01-22 23:11:00,272 - INFO - trainer.py:123 - train_model() - **************************************************
2023-01-22 23:11:00,272 - INFO - trainer.py:124 - train_model() - TRAIN RECORD:
2023-01-22 23:11:00,272 - INFO - trainer.py:125 - train_model() - Fold: 4
2023-01-22 23:11:00,272 - INFO - trainer.py:126 - train_model() - Epoch: 006 [  61/110 ( 55%)]
2023-01-22 23:11:00,293 - INFO - trainer.py:130 - train_model() - Train Loss: 0.88051(1.88721)
2023-01-22 23:11:00,293 - INFO - trainer.py:131 - train_model() - Grad: 38405.992
2023-01-22 23:11:00,293 - INFO - trainer.py:132 - train_model() - LR: 0.0000126905
2023-01-22 23:11:00,293 - INFO - trainer.py:133 - train_model() - Time: 0:07:39
2023-01-22 23:11:00,293 - INFO - trainer.py:134 - train_model() - **************************************************
2023-01-22 23:11:03,000 - INFO - trainer.py:190 - evaluate() - **************************************************
2023-01-22 23:11:03,000 - INFO - trainer.py:191 - evaluate() - Valid RECORD:
2023-01-22 23:11:03,000 - INFO - trainer.py:192 - evaluate() - Fold: 4
2023-01-22 23:11:03,000 - INFO - trainer.py:193 - evaluate() - Epoch: 006 [7/7 (100%)]
2023-01-22 23:11:03,000 - INFO - trainer.py:197 - evaluate() - Valid Loss: 1.87243(2.11837)
2023-01-22 23:11:03,000 - INFO - trainer.py:198 - evaluate() - Macro F1: 0.4863
2023-01-22 23:11:03,000 - INFO - trainer.py:199 - evaluate() - Time: 0:00:03
2023-01-22 23:11:03,000 - INFO - trainer.py:200 - evaluate() - **************************************************
2023-01-22 23:11:03,000 - INFO - function_utils.py:301 - __call__() - EarlyStopping counter: 1 out of 6
2023-01-22 23:11:36,720 - INFO - trainer.py:123 - train_model() - **************************************************
2023-01-22 23:11:36,720 - INFO - trainer.py:124 - train_model() - TRAIN RECORD:
2023-01-22 23:11:36,720 - INFO - trainer.py:125 - train_model() - Fold: 4
2023-01-22 23:11:36,720 - INFO - trainer.py:126 - train_model() - Epoch: 006 [ 110/110 (100%)]
2023-01-22 23:11:36,740 - INFO - trainer.py:130 - train_model() - Train Loss: 1.67806(1.81789)
2023-01-22 23:11:36,740 - INFO - trainer.py:131 - train_model() - Grad: 142885.906
2023-01-22 23:11:36,741 - INFO - trainer.py:132 - train_model() - LR: 0.0000123574
2023-01-22 23:11:36,741 - INFO - trainer.py:133 - train_model() - Time: 0:08:15
2023-01-22 23:11:36,741 - INFO - trainer.py:134 - train_model() - **************************************************
2023-01-22 23:11:39,451 - INFO - trainer.py:190 - evaluate() - **************************************************
2023-01-22 23:11:39,451 - INFO - trainer.py:191 - evaluate() - Valid RECORD:
2023-01-22 23:11:39,451 - INFO - trainer.py:192 - evaluate() - Fold: 4
2023-01-22 23:11:39,451 - INFO - trainer.py:193 - evaluate() - Epoch: 006 [7/7 (100%)]
2023-01-22 23:11:39,451 - INFO - trainer.py:197 - evaluate() - Valid Loss: 1.86627(2.09597)
2023-01-22 23:11:39,451 - INFO - trainer.py:198 - evaluate() - Macro F1: 0.4923
2023-01-22 23:11:39,451 - INFO - trainer.py:199 - evaluate() - Time: 0:00:03
2023-01-22 23:11:39,452 - INFO - trainer.py:200 - evaluate() - **************************************************
2023-01-22 23:11:39,452 - INFO - function_utils.py:301 - __call__() - EarlyStopping counter: 2 out of 6
2023-01-22 23:12:21,724 - INFO - trainer.py:123 - train_model() - **************************************************
2023-01-22 23:12:21,725 - INFO - trainer.py:124 - train_model() - TRAIN RECORD:
2023-01-22 23:12:21,725 - INFO - trainer.py:125 - train_model() - Fold: 4
2023-01-22 23:12:21,725 - INFO - trainer.py:126 - train_model() - Epoch: 007 [  61/110 ( 55%)]
2023-01-22 23:12:21,746 - INFO - trainer.py:130 - train_model() - Train Loss: 0.72208(1.73839)
2023-01-22 23:12:21,747 - INFO - trainer.py:131 - train_model() - Grad: 33226.160
2023-01-22 23:12:21,747 - INFO - trainer.py:132 - train_model() - LR: 0.0000118977
2023-01-22 23:12:21,747 - INFO - trainer.py:133 - train_model() - Time: 0:09:00
2023-01-22 23:12:21,747 - INFO - trainer.py:134 - train_model() - **************************************************
2023-01-22 23:12:24,457 - INFO - trainer.py:190 - evaluate() - **************************************************
2023-01-22 23:12:24,457 - INFO - trainer.py:191 - evaluate() - Valid RECORD:
2023-01-22 23:12:24,457 - INFO - trainer.py:192 - evaluate() - Fold: 4
2023-01-22 23:12:24,457 - INFO - trainer.py:193 - evaluate() - Epoch: 007 [7/7 (100%)]
2023-01-22 23:12:24,457 - INFO - trainer.py:197 - evaluate() - Valid Loss: 1.88761(2.07900)
2023-01-22 23:12:24,457 - INFO - trainer.py:198 - evaluate() - Macro F1: 0.5235
2023-01-22 23:12:24,457 - INFO - trainer.py:199 - evaluate() - Time: 0:00:03
2023-01-22 23:12:24,457 - INFO - trainer.py:200 - evaluate() - **************************************************
2023-01-22 23:13:03,070 - INFO - trainer.py:123 - train_model() - **************************************************
2023-01-22 23:13:03,070 - INFO - trainer.py:124 - train_model() - TRAIN RECORD:
2023-01-22 23:13:03,070 - INFO - trainer.py:125 - train_model() - Fold: 4
2023-01-22 23:13:03,070 - INFO - trainer.py:126 - train_model() - Epoch: 007 [ 110/110 (100%)]
2023-01-22 23:13:03,092 - INFO - trainer.py:130 - train_model() - Train Loss: 0.03466(1.67994)
2023-01-22 23:13:03,092 - INFO - trainer.py:131 - train_model() - Grad: 3402.593
2023-01-22 23:13:03,092 - INFO - trainer.py:132 - train_model() - LR: 0.0000114949
2023-01-22 23:13:03,092 - INFO - trainer.py:133 - train_model() - Time: 0:09:41
2023-01-22 23:13:03,092 - INFO - trainer.py:134 - train_model() - **************************************************
2023-01-22 23:13:05,797 - INFO - trainer.py:190 - evaluate() - **************************************************
2023-01-22 23:13:05,797 - INFO - trainer.py:191 - evaluate() - Valid RECORD:
2023-01-22 23:13:05,797 - INFO - trainer.py:192 - evaluate() - Fold: 4
2023-01-22 23:13:05,797 - INFO - trainer.py:193 - evaluate() - Epoch: 007 [7/7 (100%)]
2023-01-22 23:13:05,797 - INFO - trainer.py:197 - evaluate() - Valid Loss: 1.87856(2.08946)
2023-01-22 23:13:05,797 - INFO - trainer.py:198 - evaluate() - Macro F1: 0.5189
2023-01-22 23:13:05,797 - INFO - trainer.py:199 - evaluate() - Time: 0:00:03
2023-01-22 23:13:05,797 - INFO - trainer.py:200 - evaluate() - **************************************************
2023-01-22 23:13:05,797 - INFO - function_utils.py:301 - __call__() - EarlyStopping counter: 1 out of 6
2023-01-22 23:13:48,092 - INFO - trainer.py:123 - train_model() - **************************************************
2023-01-22 23:13:48,092 - INFO - trainer.py:124 - train_model() - TRAIN RECORD:
2023-01-22 23:13:48,092 - INFO - trainer.py:125 - train_model() - Fold: 4
2023-01-22 23:13:48,092 - INFO - trainer.py:126 - train_model() - Epoch: 008 [  61/110 ( 55%)]
2023-01-22 23:13:48,114 - INFO - trainer.py:130 - train_model() - Train Loss: 0.69412(1.61424)
2023-01-22 23:13:48,115 - INFO - trainer.py:131 - train_model() - Grad: 40554.656
2023-01-22 23:13:48,115 - INFO - trainer.py:132 - train_model() - LR: 0.0000109559
2023-01-22 23:13:48,115 - INFO - trainer.py:133 - train_model() - Time: 0:10:26
2023-01-22 23:13:48,115 - INFO - trainer.py:134 - train_model() - **************************************************
2023-01-22 23:13:50,823 - INFO - trainer.py:190 - evaluate() - **************************************************
2023-01-22 23:13:50,823 - INFO - trainer.py:191 - evaluate() - Valid RECORD:
2023-01-22 23:13:50,824 - INFO - trainer.py:192 - evaluate() - Fold: 4
2023-01-22 23:13:50,824 - INFO - trainer.py:193 - evaluate() - Epoch: 008 [7/7 (100%)]
2023-01-22 23:13:50,824 - INFO - trainer.py:197 - evaluate() - Valid Loss: 1.91480(2.12513)
2023-01-22 23:13:50,824 - INFO - trainer.py:198 - evaluate() - Macro F1: 0.5049
2023-01-22 23:13:50,824 - INFO - trainer.py:199 - evaluate() - Time: 0:00:03
2023-01-22 23:13:50,824 - INFO - trainer.py:200 - evaluate() - **************************************************
2023-01-22 23:13:50,824 - INFO - function_utils.py:301 - __call__() - EarlyStopping counter: 2 out of 6
2023-01-22 23:14:24,576 - INFO - trainer.py:123 - train_model() - **************************************************
2023-01-22 23:14:24,576 - INFO - trainer.py:124 - train_model() - TRAIN RECORD:
2023-01-22 23:14:24,576 - INFO - trainer.py:125 - train_model() - Fold: 4
2023-01-22 23:14:24,577 - INFO - trainer.py:126 - train_model() - Epoch: 008 [ 110/110 (100%)]
2023-01-22 23:14:24,601 - INFO - trainer.py:130 - train_model() - Train Loss: 0.06995(1.56794)
2023-01-22 23:14:24,601 - INFO - trainer.py:131 - train_model() - Grad: 7275.329
2023-01-22 23:14:24,601 - INFO - trainer.py:132 - train_model() - LR: 0.0000104958
2023-01-22 23:14:24,601 - INFO - trainer.py:133 - train_model() - Time: 0:11:03
2023-01-22 23:14:24,601 - INFO - trainer.py:134 - train_model() - **************************************************
2023-01-22 23:14:27,311 - INFO - trainer.py:190 - evaluate() - **************************************************
2023-01-22 23:14:27,311 - INFO - trainer.py:191 - evaluate() - Valid RECORD:
2023-01-22 23:14:27,311 - INFO - trainer.py:192 - evaluate() - Fold: 4
2023-01-22 23:14:27,311 - INFO - trainer.py:193 - evaluate() - Epoch: 008 [7/7 (100%)]
2023-01-22 23:14:27,311 - INFO - trainer.py:197 - evaluate() - Valid Loss: 1.92712(2.12256)
2023-01-22 23:14:27,311 - INFO - trainer.py:198 - evaluate() - Macro F1: 0.5072
2023-01-22 23:14:27,311 - INFO - trainer.py:199 - evaluate() - Time: 0:00:03
2023-01-22 23:14:27,311 - INFO - trainer.py:200 - evaluate() - **************************************************
2023-01-22 23:14:27,311 - INFO - function_utils.py:301 - __call__() - EarlyStopping counter: 3 out of 6
2023-01-22 23:15:09,601 - INFO - trainer.py:123 - train_model() - **************************************************
2023-01-22 23:15:09,601 - INFO - trainer.py:124 - train_model() - TRAIN RECORD:
2023-01-22 23:15:09,601 - INFO - trainer.py:125 - train_model() - Fold: 4
2023-01-22 23:15:09,601 - INFO - trainer.py:126 - train_model() - Epoch: 009 [  61/110 ( 55%)]
2023-01-22 23:15:09,621 - INFO - trainer.py:130 - train_model() - Train Loss: 0.77320(1.51428)
2023-01-22 23:15:09,622 - INFO - trainer.py:131 - train_model() - Grad: 28112.271
2023-01-22 23:15:09,622 - INFO - trainer.py:132 - train_model() - LR: 0.0000098939
2023-01-22 23:15:09,622 - INFO - trainer.py:133 - train_model() - Time: 0:11:48
2023-01-22 23:15:09,622 - INFO - trainer.py:134 - train_model() - **************************************************
2023-01-22 23:15:12,329 - INFO - trainer.py:190 - evaluate() - **************************************************
2023-01-22 23:15:12,330 - INFO - trainer.py:191 - evaluate() - Valid RECORD:
2023-01-22 23:15:12,330 - INFO - trainer.py:192 - evaluate() - Fold: 4
2023-01-22 23:15:12,330 - INFO - trainer.py:193 - evaluate() - Epoch: 009 [7/7 (100%)]
2023-01-22 23:15:12,330 - INFO - trainer.py:197 - evaluate() - Valid Loss: 1.90621(2.10726)
2023-01-22 23:15:12,330 - INFO - trainer.py:198 - evaluate() - Macro F1: 0.5133
2023-01-22 23:15:12,330 - INFO - trainer.py:199 - evaluate() - Time: 0:00:03
2023-01-22 23:15:12,330 - INFO - trainer.py:200 - evaluate() - **************************************************
2023-01-22 23:15:12,330 - INFO - function_utils.py:301 - __call__() - EarlyStopping counter: 4 out of 6
2023-01-22 23:15:46,032 - INFO - trainer.py:123 - train_model() - **************************************************
2023-01-22 23:15:46,032 - INFO - trainer.py:124 - train_model() - TRAIN RECORD:
2023-01-22 23:15:46,032 - INFO - trainer.py:125 - train_model() - Fold: 4
2023-01-22 23:15:46,032 - INFO - trainer.py:126 - train_model() - Epoch: 009 [ 110/110 (100%)]
2023-01-22 23:15:46,054 - INFO - trainer.py:130 - train_model() - Train Loss: 0.42484(1.47448)
2023-01-22 23:15:46,055 - INFO - trainer.py:131 - train_model() - Grad: 29245.490
2023-01-22 23:15:46,055 - INFO - trainer.py:132 - train_model() - LR: 0.0000093904
2023-01-22 23:15:46,055 - INFO - trainer.py:133 - train_model() - Time: 0:12:24
2023-01-22 23:15:46,055 - INFO - trainer.py:134 - train_model() - **************************************************
2023-01-22 23:15:48,763 - INFO - trainer.py:190 - evaluate() - **************************************************
2023-01-22 23:15:48,763 - INFO - trainer.py:191 - evaluate() - Valid RECORD:
2023-01-22 23:15:48,763 - INFO - trainer.py:192 - evaluate() - Fold: 4
2023-01-22 23:15:48,763 - INFO - trainer.py:193 - evaluate() - Epoch: 009 [7/7 (100%)]
2023-01-22 23:15:48,763 - INFO - trainer.py:197 - evaluate() - Valid Loss: 1.93121(2.12180)
2023-01-22 23:15:48,763 - INFO - trainer.py:198 - evaluate() - Macro F1: 0.5065
2023-01-22 23:15:48,763 - INFO - trainer.py:199 - evaluate() - Time: 0:00:03
2023-01-22 23:15:48,764 - INFO - trainer.py:200 - evaluate() - **************************************************
2023-01-22 23:15:48,764 - INFO - function_utils.py:301 - __call__() - EarlyStopping counter: 5 out of 6
2023-01-22 23:16:31,102 - INFO - trainer.py:123 - train_model() - **************************************************
2023-01-22 23:16:31,102 - INFO - trainer.py:124 - train_model() - TRAIN RECORD:
2023-01-22 23:16:31,102 - INFO - trainer.py:125 - train_model() - Fold: 4
2023-01-22 23:16:31,102 - INFO - trainer.py:126 - train_model() - Epoch: 010 [  61/110 ( 55%)]
2023-01-22 23:16:31,126 - INFO - trainer.py:130 - train_model() - Train Loss: 0.72173(1.43039)
2023-01-22 23:16:31,127 - INFO - trainer.py:131 - train_model() - Grad: 58245.520
2023-01-22 23:16:31,127 - INFO - trainer.py:132 - train_model() - LR: 0.0000087438
2023-01-22 23:16:31,127 - INFO - trainer.py:133 - train_model() - Time: 0:13:09
2023-01-22 23:16:31,127 - INFO - trainer.py:134 - train_model() - **************************************************
2023-01-22 23:16:33,833 - INFO - trainer.py:190 - evaluate() - **************************************************
2023-01-22 23:16:33,833 - INFO - trainer.py:191 - evaluate() - Valid RECORD:
2023-01-22 23:16:33,833 - INFO - trainer.py:192 - evaluate() - Fold: 4
2023-01-22 23:16:33,834 - INFO - trainer.py:193 - evaluate() - Epoch: 010 [7/7 (100%)]
2023-01-22 23:16:33,834 - INFO - trainer.py:197 - evaluate() - Valid Loss: 1.92548(2.11638)
2023-01-22 23:16:33,834 - INFO - trainer.py:198 - evaluate() - Macro F1: 0.5225
2023-01-22 23:16:33,834 - INFO - trainer.py:199 - evaluate() - Time: 0:00:03
2023-01-22 23:16:33,834 - INFO - trainer.py:200 - evaluate() - **************************************************
2023-01-22 23:16:33,834 - INFO - function_utils.py:301 - __call__() - EarlyStopping counter: 6 out of 6
2023-01-22 23:16:33,834 - INFO - trainer.py:144 - train_model() - ========== fold: 4 result ==========
2023-01-22 23:16:33,834 - INFO - trainer.py:145 - train_model() - {'[fold4] valid best score taskC': 0.5234861408822125}
2023-01-22 23:16:33,834 - INFO - trainer.py:148 - train_model() - {'[fold4] valid best score taskC': 0.5234861408822125}
